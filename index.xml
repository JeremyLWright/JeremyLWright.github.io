<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code Strokes</title>
    <link>http://codestrokes.com/</link>
    <description>Recent content on Code Strokes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Feb 2015 03:46:55 +0000</lastBuildDate>
    <atom:link href="http://codestrokes.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Introduction to Pointers</title>
      <link>http://codestrokes.com/2015/02/introduction-to-pointers/</link>
      <pubDate>Tue, 17 Feb 2015 03:46:55 +0000</pubDate>
      
      <guid>http://codestrokes.com/2015/02/introduction-to-pointers/</guid>
      <description>&lt;p&gt;Please see my introduction to pointers at &lt;a href=&#34;https://www.youtube.com/watch?v=mkYBz5Db-Ok&#34;&gt;https://www.youtube.com/watch?v=mkYBz5Db-Ok&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Property Testing in C&#43;&#43;</title>
      <link>http://codestrokes.com/2014/09/property-testing-in-c/</link>
      <pubDate>Wed, 03 Sep 2014 23:00:00 -0700</pubDate>
      
      <guid>http://codestrokes.com/2014/09/property-testing-in-c/</guid>
      <description>&lt;p&gt;
Currently, I&#39;m on a testing kick. One might say tests are shiny. I don&#39;t
know if they are really shiny as much as I found another cool use for
uniform_int_distribution&lt;&gt;. A use which, as a side effect, might make me
appear to be a better software developer. (This assumes a negative bug rate is
proportional to better software). I&#39;ve started playing with Property Testing.
Property Testing is a form of unit testing where the programmers defines
properties, or invariants about the code. A &lt;del&gt;framework&lt;/del&gt; library (ok,
seriously its a framework because it calls your code) generates random
constrained inputs and calls your test functions. It&#39;s pretty cool, and while
I was playing around with the framework, I found a real bug, related to my
ignorance of C++&#39;s auto type deduction.&lt;/p&gt;&lt;p&gt;Let&#39;s steal a simple
example from my CSE 565 Software Verification class: a payroll function. Here
is the specification:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Design a function that calculates
payroll for an employee.&lt;/p&gt; &lt;h3&gt;Inputs&lt;/h3&gt; &lt;p&gt;Employee Id number&lt;br&gt;Number
of Hours&lt;/p&gt; &lt;h3&gt;Outputs&lt;/h3&gt; &lt;p&gt;Amount to pay employee as a floating point
value.&lt;/p&gt; &lt;h3&gt;Constraints&lt;/h3&gt; &lt;p&gt;Pay is calculated at $10 for standard time,
$15 for overtime over 40 hours.&lt;br&gt;Overtime starts over 40 hours&lt;br&gt;Maximum
number of hours is 100.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;For this demonstration, I’m using
a C++ port of Haskell’s QuickCheck, CppQuickCheck (&lt;a
title=&#34;https://github.com/grogers0/CppQuickCheck&#34;
href=&#34;https://github.com/grogers0/CppQuickCheck&#34;&gt;https://github.com/grogers0/CppQuickCheck&lt;/a&gt;,
my fork and the examples in this post are available here: &lt;a
title=&#34;https://github.com/jwright85/CppQuickCheck&#34;
href=&#34;https://github.com/jwright85/CppQuickCheck&#34;&gt;https://github.com/jwright85/CppQuickCheck&lt;/a&gt;).
QuickCheck was designed by John Hughes who has gone on to support a commercial
version of the library for verifying (and validating) automotive requirements
for Volvo (&lt;a title=&#34;http://vimeo.com/68331689&#34;
href=&#34;http://vimeo.com/68331689&#34;&gt;http://vimeo.com/68331689&lt;/a&gt;).&amp;nbsp; His
presentations have motivated me to try this testing strategy for my own
programs. Lets start with a quick implementation for our payroll function.
We&#39;ll then apply properties against the function until we are satisfied with
the implementation. Although property testing can provide more confidence in
an implementation Dijkstra&#39;s famous quote still stands, &#34;Testing shows the
presence, not the absence of bugs.&#34;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours) { 
    if(hours &amp;gt; 100) 
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;); 
    auto overtime = hours - 40; 
    return hours * 10 + overtime * 15; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is obviously wrong, but let&amp;rsquo;s suspend that for a moment and think about
properties i.e. invariants we can verify.&lt;/p&gt;

&lt;p&gt;The first property verifies that we do not write a negative paycheck. The
return type of the function is float, which supports negative values even
though the output domain of our specification forbids it. Lets write
a property over the valid input range of hours that we don&amp;rsquo;t generate negative
pay.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestPositivePay : cppqc::Property
{ 
    PropTestPositivePay() : Property(cppqc::choose(0, 100)) {} 
    
    bool check(const int &amp;amp;  hours) const { 
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5}; 
        return uut::payroll(id, hours) &amp;gt;= 0; 
    }

    std::string name() const
    {
        return &amp;quot;Pay should be positive&amp;quot;;
    }

    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }

    bool trivial(const int &amp;amp;  v) const
    {
        return v &amp;lt; 40;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the input range of this function is small (101 values) so we could run an exhaustive test, but for larger input domains the random generators can really shine. &lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jwright@phaseshift-linux:~/art/CppQuickCheck/b$ ./examples/testPayroll
* Checking property &amp;quot;Pay should be positive&amp;quot; ...
* *** Failed! Falsifiable after 32 tests for input:
*   0: 24
*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cool it found that an input of 0 will falsify the test. Lets add some more tests.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s add a property that verifies for the input range of overtime that the
function doesn’t pay all hours at the $10 rate nor all the hours at the $15
rate. The correct implementation is some mixture of these two.&amp;nbsp; This
brings me to a subtle point when I first heard of property-testing when
studying Haskell. In my naiveté I thought to myself, &amp;ldquo;If I have a model that
verifies the unit under test, aren&amp;rsquo;t I duplicating the implementation?&amp;rdquo;
Furthermore, if I duplicate the implementation, how can I be sure I&amp;rsquo;m not
making the same bugs twice. One response I found online, “we test our C code
in Erlang. It&amp;rsquo;s unlikely to make the same mistake in two separate languages.”
I was wrong however, you don&amp;rsquo;t have to duplicate the functionality. You can
steer the generator to generate data within a range over which a simple
property will be true. Multiple properties together then test the fuller input
domain without requiring 1 single verifier to duplicate behavior. This
property doesn’t exactly know what the correct payroll is. It isn’t
calculating the correct value, it’s just excluding values that it cannot be.
&lt;/p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestOvertimeRateHigher : cppqc::Property 
{ 
    PropTestOvertimeRateHigher()
    :
    Property(cppqc::choose(41, 100)) {} 
    
    bool check(const int &amp;amp;  hours) const { 
    
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5}; 
        auto pay = uut::payroll(id, hours); 
        return pay &amp;gt; hours * 10 &amp;amp;&amp;amp;  pay &amp;lt; hours * 15; //You cannot get paid all overtime or all standard pay
    }

    std::string name() const
    {
        return &amp;quot;You cannot get paid all overtime, or all std time&amp;quot;;
    }

    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }

    bool trivial(const int &amp;amp;  v) const
    {
        return v == 40;
    }

};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Following this thought of excluding a range and testing a simpler property,
lets test the payroll without considering overtime. In this case the
calculation is simple so we can provide a full implementation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestIgnoreOvertime : cppqc::Property
{
    PropTestIgnoreOvertime() : Property(cppqc::choose(0, 40)) {}
    bool check(const int &amp;amp;  hours) const
    {
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5};
        auto pay = uut::payroll(id, hours);
        return pay == hours * 10;
    }

    std::string name() const
    {
        return &amp;quot;Not working overtime makes the math easy.&amp;quot;;
    }
    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }
    bool trivial(const int &amp;amp;  v) const
    {
        return v == 40;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We run the tests a few times and see the failing test cases. These data are random. Running the test multiple times fails differently, but minimization results in the same or similar values each time to help the programmer debug. So let&amp;rsquo;s fix this code and watch the tests pass to avoid the &lt;a href=&#34;http://www.codestrokes.com/2014/08/what-is-a-unit-test/&#34;&gt;mockery and scandal of code review&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40;
    if(overtime &amp;gt; 0)
        return hours * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
*** Failed! Falsifiable after 1 test and 1 shrink for input:
0: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be honest, while setting up the tests for this post I fully expected the
tests to start passing and this article would end here. Instead I learned some
real value on using these properties as a debugging and design tool. Let&amp;rsquo;s add
a printf to the code to get a sense what&amp;rsquo;s happening&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
Overtime: 18446744073709551576 &amp;lt;--- Whoa what happened there?
*** Failed! Falsifiable after 1 test and 1 shrink for input:
0: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Overtime seems to be an unsigned value, and passing in 0 causes the value to wrap around. The rule (&lt;a href=&#34;http://scottmeyers.blogspot.com/2013/07/when-decltype-meets-auto.html&#34;&gt;http://scottmeyers.blogspot.com/2013/07/when-decltype-meets-auto.html&lt;/a&gt;) assures that overtime becomes a size_t since hours is size_t. We can force floating conversion by stating that 40 is a floating point number.&lt;/p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40.0; //&amp;lt;-- Force implicit floating point cast
    if(overtime &amp;gt; 0)
        return hours * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Pay should be positive&amp;quot; ...
+++ OK, passed 100 tests (40% trivial).
* Checking property &amp;quot;You cannot get paid all overtime, or all std time&amp;quot; ...
*** Failed! Falsifiable after 1 test and 1 shrink for input:
  0: 60
* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
+++ OK, passed 100 tests.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Argh! Still wrong? The property must be wrong. Notice that the properties are quite simple. No single test verifies the full range, but the properties provide useful documentation and make it easy to reason about the code. The properties are probably correct then. &amp;hellip;yeah, it wasn&amp;rsquo;t the property…&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t  5 ,&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40.0;
    if(overtime &amp;gt; 0)
        return (hours - overtime) * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Pay should be positive&amp;quot; ...
+++ OK, passed 100 tests (40% trivial).
* Checking property &amp;quot;You cannot get paid all overtime, or all std time&amp;quot; ...
+++ OK, passed 100 tests.
* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
+++ OK, passed 100 tests.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I started this article wanting to post a simple tutorial on Property testing,
instead I learned to be a bit more careful using auto, and even when the
function is simple, programmers can make mistakes. For the final logic error,
the failing input was 60. Thinking about my directed test method, I would
divide the input into equivalence domains and test the boundary values. For
this input, I would divide standard time to the beginning of overtime. For
directed tests I would have written tests for: 0, 39, 40 41, 99, 100, and 101.
I would have missed the 60 hours bug, and there is the possibility that
I missed typed the numbers on my calculator and type in a wrong expected
value. This example is quite simple but still an interesting demonstration of
property testing. I&amp;rsquo;m looking forward to applying property testing to my next
project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What is a Unit Test?</title>
      <link>http://codestrokes.com/2014/08/what-is-a-unit-test/</link>
      <pubDate>Thu, 28 Aug 2014 05:58:26 +0000</pubDate>
      
      <guid>http://codestrokes.com/2014/08/what-is-a-unit-test/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m taking a Software Testing and Verification course as part of my Master&amp;rsquo;s work. Our first assignment was to write a short paper describing a unit test, then implement selection sort and test it under that philosophy. Sarcastically, I commented to my colleagues the triviality of this question. The first response was, &amp;ldquo;Wow, I don&amp;rsquo;t think that is such an easy question.&amp;rdquo; A technical discussion ensued. This is that log.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;&lt;/p&gt;

&lt;blockquote&gt;Definition 1:
Given a function in the mathematical sense, i.e. no side-effect, a unit test treats the function as a black box and passes it input and expects a given output. Conversely, an integration test tests entites which are not pure functions using a mock to control state.&lt;/blockquote&gt;

&lt;blockquote&gt;Definition 2:
A unit test de-tangles dependencies so one can test a submodules prior to merging ([complecting](http://www.infoq.com/presentations/Simple-Made-Easy)) it&#39;s functionality with another module.&lt;/blockquote&gt;

&lt;blockquote&gt;[Wikipedia](http://en.wikipedia.org/wiki/Unit_testing):
In computer programming, unit testing is a software testing method by which individual units of source code, sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures are tested to determine if they are fit for use&lt;/blockquote&gt;

&lt;p&gt;I proposed the first definition above, which is mostly influence from my Haskell QuickCheck experience.  During lecture today the professor presented levels of testing.&lt;/p&gt;

&lt;p&gt;Unit Testing
Integration Testing
System Testing
Alpha Testing
Beta Testing&lt;/p&gt;

&lt;p&gt;The theme here? Each successive layer of testing include more modules and more functionality. Unit testing is the most basic. It doesn&amp;rsquo;t  have to provide a pure interface, it can be dirty, it can have side effects, but before I promote some software module to the next stage, I want some confidence its working. The professor went on to ask, &amp;ldquo;What if we had a test team, a separately paid person to write the unit tests? Would that work? Would that be a good idea?&amp;rdquo;&lt;/p&gt;

&lt;p&gt;My initial response was, &amp;ldquo;No! those tests are mine!&amp;rdquo; This is my definition of a unit test, private tests.&lt;/p&gt;

&lt;p&gt;Definition I hold now:
A unit test is a test to provide the developer some confidence a region of code works as intended before other people see the code and the developer is open to mockery and scandal.&lt;/p&gt;

&lt;p&gt;This definition supposed unit tests are more emotional, or egocentric than technical, but when I think about how, and where I choose to unit test heavily, and where I choose to test more lightly it centers around areas of code I would be embarrassed to get wrong. To get back to the homework assignment, the first goal was to implement selection sort:&lt;/p&gt;

&lt;p&gt;Unit under test&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;iterator&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;algorithm&amp;gt;

template &amp;lt;typename InputIterator&amp;gt;
void selection_sort(InputIterator b, InputIterator e)
{
    for(InputIterator c = b; c != e ; ++c){
        auto m = std::min_element(c, e);
        std::swap(*m, *c);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Selection sort is pretty naive (O(n^2)) but its straight-forward to implement, and std::algorithms make it even easier to understand. As a side note, this is the real strength of the STL algorithms: clarity. This code has very few opportunities for bugs because of the reliance on STL algorithms. Additionally, it&amp;rsquo;s readable! Additionally, it&amp;rsquo;s templated so everyone will think you are a badass (unless there is a bug in it, in which case they judge you every time you whip out the &lt;em&gt;typename&lt;/em&gt;). To prevent this horrific alternate future we can unit test.  Furthermore, we can take a page from the FPGA/ASIC guys and use randomized tests. (As opposed to direct tests).&lt;/p&gt;

&lt;p&gt;Randomized tests construct random input and feed it through the unit under test.  A secondary implementation of the function verifies the result. In this case we are luck that the invariant of a &amp;ldquo;sorted list&amp;rdquo; is easy to check.  In fact there is a standard algorithm for it: std::is_sorted().&lt;/p&gt;

&lt;p&gt;Using GTest we construct a parameterized test. We then construct a list of random vectors and instantiate the test with the 10000 separate vectors. GTest provides a lot of value here.  If a single test fails, GTest will print out the parameter value when that particular test failed the build. Since we are using random data, this is critical so we can setup regression tests.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;quot;sort.hpp&amp;quot;
#include &amp;quot;gtest/gtest.h&amp;quot;
#include &amp;lt;vector&amp;gt;
#include &amp;lt;random&amp;gt;
#include &amp;lt;limits&amp;gt;
#include &amp;lt;cassert&amp;gt;
#include &amp;lt;iostream&amp;gt;

using TestInput = std::vector&amp;lt;int&amp;gt;;

class RandomizedTest : public testing::TestWithParam&amp;lt;TestInput&amp;gt; {};
TEST_P(RandomizedTest, Sorting)
{
   auto vs = GetParam();
   selection_sort(std::begin(vs), std::end(vs));
   ASSERT_TRUE(std::is_sorted(std::begin(vs), std::end(vs)));
}

std::vector&amp;lt;std::vector&amp;lt;int&amp;gt;&amp;gt; GenerateTestCases()
{
 std::vector&amp;lt;TestInput&amp;gt; test_cases;
 std::numeric_limits&amp;lt;int&amp;gt; limits;

 std::mt19937 engine(time(0)); // Fixed seed of 0
 std::uniform_int_distribution&amp;lt;int&amp;gt; range_dist(0,1500);
 std::uniform_int_distribution&amp;lt;int&amp;gt; element_dist(0, limits.max());

 size_t n = 10000;
 auto f = [&amp;amp;](){return element_dist(engine);};
 std::generate_n(std::back_inserter(test_cases), n, 
     [&amp;amp;](){ 
         TestInput vs;
         std::generate_n(std::back_inserter(vs), range_dist(engine), f);
         return vs;
     });
 return test_cases;
}

INSTANTIATE_TEST_CASE_P(
 GeneralAndSpecial,
 RandomizedTest,
 testing::ValuesIn(GenerateTestCases()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Build Script&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;project(hw1)

include(ExternalProject)
ExternalProject_Add(
    GTest 
    URL http://googletest.googlecode.com/files/gtest-1.7.0.zip
    INSTALL_COMMAND &amp;quot;&amp;quot;
    )

ExternalProject_Get_Property(GTest source_dir)
include_directories(${source_dir}/include)


ExternalProject_Get_Property(GTest binary_dir)
link_directories(${binary_dir})


set(CMAKE_CXX_FLAGS &amp;quot;-O3 -std=gnu++11&amp;quot;)
add_executable(hw1 main.cpp)
add_executable(test test.cpp)
add_dependencies(test GTest)
target_link_libraries(test gtest gtest_main pthread rt)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These tests take nearly 5 seconds to run, but randomization gives us another cool feature. Typically with directed tests, once the tests pass the probability of that test failing int he future is pretty low. Randomized tests are different every time you run them. While the invariant of the input are constant the input itself changes greatly, and exercises code in ways a human may not imagine.&lt;/p&gt;

&lt;p&gt;tldr;
- Unit tests help you save face.
- Random tests kick directed tests&amp;rsquo; teeth in.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello Project Euler, Sorry I doubted you</title>
      <link>http://codestrokes.com/2014/08/hello-project-euler-sorry-i-doubted-you/</link>
      <pubDate>Thu, 28 Aug 2014 05:04:52 +0000</pubDate>
      
      <guid>http://codestrokes.com/2014/08/hello-project-euler-sorry-i-doubted-you/</guid>
      <description>&lt;p&gt;Project Euler returns with full functionality including new problems! Thank you Project Euler for not giving up on this awesome project. &lt;a href=&#34;http://projecteuler.net/news&#34;&gt;http://projecteuler.net/news&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Goodbye Project Euler</title>
      <link>http://codestrokes.com/2014/06/goodbye-project-euler/</link>
      <pubDate>Wed, 18 Jun 2014 15:42:22 +0000</pubDate>
      
      <guid>http://codestrokes.com/2014/06/goodbye-project-euler/</guid>
      <description>&lt;p&gt;A group of friends and I have been working on project euler for about a year now. I learned a great deal from this fantastic project, and it was the first time I was able to get a real handle on Haskell. Project Euler taught me make. It taught me better performance reporting techniques, honed my octave, and got me over that initial mind bending hump of Haskell. Thank you Project Euler, you will be missed.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2014/06/euler.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2014/06/euler-1024x902.png&#34; alt=&#34;Project Euler&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Design for Testability via Security </title>
      <link>http://codestrokes.com/2014/05/design-for-testability-via-security/</link>
      <pubDate>Sat, 03 May 2014 20:56:49 +0000</pubDate>
      
      <guid>http://codestrokes.com/2014/05/design-for-testability-via-security/</guid>
      <description>

&lt;p&gt;I was discussing bootloader design with a colleague of mine the other day. We were attempting to load new a third-party hardware component. The device has a poor protocol, and a useless verification step. This discussion got me thinking however how the concepts used to build a strong self-enforcing security protocol, also apply to building a testable, and reliable communication protocol. Thus, security helps us build better products not because they are secure, but because they are verifiable.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
This idea initially struck me as strange, since many of the secure software interfaces I&amp;rsquo;ve used in the past, are quite obtuse. This is not a fundamental aspect of security, by rather an artifact of poor design (think OpenSSL). This is sad, since security is already a difficult concept, and requires a great deal of study to maintain throughout the life cycle of a product. Secure interfaces should make security easier, not more difficult. This is however a separate rant. So back to the bootloader.&lt;/p&gt;

&lt;p&gt;This specific device is connected by a CAN bus. This is not critical to my argument except the fact that CAN is a reliable, but slow and message order is not guaranteed. In fact, within a window of 4 packets, order is essentially random. Think about this for a moment: load firmware with random message order. The goal is to design a protocol to work with this. Firmware loading fits into a three step process: Prepare, Load, Verify. This process works independent of underlying storage techniques. For example, NAND must be erased on a full page boundary, that can be done in the prepare step. Loading to a file system, Prepare might be a simple NOP.&lt;/p&gt;

&lt;p&gt;Firstly, know that the final, verification step is essential. Some environments, the bootloader runs out of RAM, if the load process fails, and the hardware reboots without verification, the bootloader may no longer function, and you just build a sweet digital brick. So verification must check that the firmware the user attempted to load, matches the firmware written to the flash. There are several mechanisms to verify this. The hardware my colleague and I are working with, simply reads the flash back to you. At a high level this sounds fine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Loader ---&amp;gt; Send Data     ---&amp;gt; Bootloader
Loader ---&amp;gt; Data Complete ---&amp;gt; Bootloader
Loader ---&amp;gt; Verify        ---&amp;gt; Bootloader
Loader &amp;lt;--- Send Data     &amp;lt;--- Bootloader
Loader Loader Verifies data matches.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remember, message order is random. If the bootloader dumps its flash back on the CAN bus, without a sequence number or flash addresses, the data that comes back is completely useless. Each data packet is intact, but is position within the overall data block is unknown. The best one can do is probabilisticly reorder the packets to attempt to get a confidence the bootloader has the same data we attempted to send. Okay, so what would be better? Lets model this as a security problem and design a secure document sending protocol.&lt;/p&gt;

&lt;h3 id=&#34;prepare:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Prepare&lt;/h3&gt;

&lt;p&gt;Alice and Bob want to exchange a document. (Any protocol can be made more &amp;ldquo;secure&amp;rdquo; by describing it with &lt;a href=&#34;https://xkcd.com/1323/&#34;&gt;Alice and Bob.&lt;/a&gt;) The communication channel is UDP, untrusted, and public. How should Alice and Bob communicate? Every security protocol starts with authentication. Bob wants to verify the sender is Alice. Alice wants to verify it&amp;rsquo;s sending the document to Bob, and not someone else. So lets negotiate a key based on a preshared secret. This will form the prepare step of our high-level bootloader model.
&lt;table &gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice generates a nonce.
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob waiting for message.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice encrypts bob_public_key(nonce_alice:sha256(nonce_alice))
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;-&amp;gt;
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;&amp;lt;-
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob decrypts the message.
Bob generates a new nonce. Bob encrypts
alice_public_key(nonce_bob:sha256(nonce_bob):nonce_alice:sha256(nonce_alice))&lt;/p&gt;

&lt;p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;Alice now has Bob&amp;rsquo;s nonce. Bob has Alice&amp;rsquo;s nonce. Any listening attacker only has 2 messages of cipher text. Bob know&amp;rsquo;s the message was sent from Alice because only Alice has Alice&amp;rsquo;s private key,thus only Alice could have made the nonce message. Bob knows the nonce was intentional because Alice included the secure hash of the nonce.&lt;/p&gt;

&lt;p&gt;This protocol is protected against replay attack since Bob decrypts the nonce and hash, and reencrypts with Alice&amp;rsquo;s public key. This allows Alice to verify Bob received her original message. Furthermore the messages are protected against manipulation because all messages include hashes. Bob, and Alice are authenticated. Additionally, they share a new, secret session key.&lt;/p&gt;

&lt;p&gt;Alice builds the session key, &amp;ldquo;sha256(nonce_bob:nonce_alice)&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;Bob builds the session key, &amp;ldquo;sha256(nonce_bob:nonce_alice)&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;Now only Bob and Alice at this time instance can have this new shared secret. Alice and Bob can now communicate securely. &lt;del&gt;Let&amp;rsquo;s load some firmware to Bob now.&lt;/del&gt; Let&amp;rsquo;s transfer a document to Bob now.&lt;/p&gt;

&lt;h3 id=&#34;transfer:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Transfer&lt;/h3&gt;

&lt;p&gt;Alice creates a document and signs it e.g. document:alice_private_key(sha256(document)).  Notice that Alice&amp;rsquo;s private key is used to encrypt here. This is correct. We want Bob to receive the document, create a hash of the document. Bob then uses Alice&amp;rsquo;s public key to &amp;ldquo;encrypt&amp;rdquo; the signature sent by Alice. He will get the plain text hash, and compare. The signature does not protect the hash i.e. it does not provide confidentiality since anyone can decrypt with the public key. Instead the signature provides integrity. The hash protects that the document was unchanged. The signature of the hash protects that the hash was computed only by Alice.&lt;/p&gt;

&lt;p&gt;Alice breaks up the document into packets to send over UDP. Each packet includes a sequence number and a hash of that message.&lt;/p&gt;

&lt;p&gt;packet = aes(session_key, i:document[i]:sha256(i:document[i]))&lt;/p&gt;

&lt;p&gt;The session key encrypts the entire message to provide confidentiality. This also strengthens the Man in the middle attack, since this session_key is ephemeral. Since it exists for only this authenticated session, an attacker cannot resend this data later to Bob. The sha256 hash provides integrity i.e. &lt;del&gt;transmission errors&lt;/del&gt; malicious corruption. Bob verifies each individual packet by calculating the has of the received document[i], and comparing it. If the packets arrive out of order, which in &lt;del&gt;CAN&lt;/del&gt; UDP they will, Bob can sort them.&lt;/p&gt;

&lt;p&gt;Once Bob has the entire message he can verify the signature.  Bob now has the document, all listeners only have cipher version of the document. Furthermore, Bob can verify the entire document is valid. Bob will &lt;del&gt;erase his flash, and load the new firmware into memory&lt;/del&gt; PROFIT!&lt;/p&gt;

&lt;h3 id=&#34;verify:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Verify&lt;/h3&gt;

&lt;p&gt;The device my colleague and I are trying to fix simply dumped the document back to Alice.  Essentially:&lt;/p&gt;

&lt;p&gt;packet = document[i]&lt;/p&gt;

&lt;p&gt;Each packet isn&amp;rsquo;t protected from corruption. The order of the document is unverifiable. The best Alice can do is attempt to verify multiple times hoping the document messages randomly converge on the document Alice originally sent. This is the same as using &lt;a href=&#34;http://en.wikipedia.org/wiki/Bogosort&#34;&gt;Bogosort&lt;/a&gt; as a verification step. Not awesome. Instead we&amp;rsquo;ve built up some very secure machinery to &lt;del&gt;load software reliably&lt;/del&gt; transfer a document securely.&lt;/p&gt;

&lt;p&gt;One method, although rather naive would be for Bob to send back the document to Alice in the same manner, encrypting each packet and the final signature. This however is very wasteful. Instead Alice only needs to confirm that Bob has the document in its entirely, that it is in the flash, and that all packets were loaded in the correct order. Bob simply needs to send a signature. Bob then reads his flash, and calculates a sha256. Bob then sends 1 message:&lt;/p&gt;

&lt;p&gt;packet = aes(session_key, bob_private_key(sha256(flash_read)))&lt;/p&gt;

&lt;p&gt;The packet is confidential because it is encrypted by aes. The message is protected from integrity because Alice already has the hash, she simple needs to verify that it matches the know value. Note that if Alice didn&amp;rsquo;t have the hash already we would include a hash of the hash to provide further integrity. Alice knows that it was Bob who verified the flash because the hash is signed with Bob&amp;rsquo;s key. Lastly, Alice knows the message is part of this load session and not a previous one replayed by an attacker because the whole message is encrypted by a session key.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Alice and Bob now have a protocol secure against a number of attacks, but how is this useful for a bootloader? Each attack can be modeled as random noise, transmission errors, or other external effects would impede the flow of traffic. Security simply provides a more common vernacular for discussing transmission issues. It&amp;rsquo;s also easier to reason about adversarial attackers rather than electrical interference. By translating the problem into a security one, we can model all these affects as &amp;ldquo;bad people&amp;rdquo; and it is a lot more fun to slay dragons, than it is to protect against some amorphous something.&lt;/p&gt;

&lt;p&gt;Okay, but what does this have to do with testability? Ah. It&amp;rsquo;s subtle, but the same process we took to make our protocol secure also made each step verifiable. For instance, the final verification step could have been as simple as Bob sending an ACK that he verified the document&amp;rsquo;s signature. This however isn&amp;rsquo;t secure. An ACK can be faked, or replayed. Instead Bob build a cryptographically secure signature for Alice to verify. From a tester&amp;rsquo;s perspective Alice is the &amp;ldquo;verifier&amp;rdquo;, and Bob generates test data. Bob cannot be trusted to verify something himself, the test must generate auditable output. Thus the same process which drove us to make a secure response, also generated a auditable one for the tester to report. Thus security is more useful than simply protecting our data, it helps us design better products.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Massively Intelligent Non-Deterministic Luminating Effortless Super Solver</title>
      <link>http://codestrokes.com/2014/02/cracking-subciphercpp/</link>
      <pubDate>Wed, 12 Feb 2014 08:50:00 -0700</pubDate>
      
      <guid>http://codestrokes.com/2014/02/cracking-subciphercpp/</guid>
      <description>&lt;p&gt;I worked the title of this article several times before I finally settled on the subtly epic heading you see above. Hopefully this title will funnel people off google into my blog (delicious SEO). I wanted to push the A.I. component of my solution because A.I. is awesome and mysterious, and cool (and can like solve jeopardy). I was quickly disillusioned however. Really, A.I. isn&amp;rsquo;t magic, rather it&amp;rsquo;s just the same thing computers have been doing for a long time: computing. Sadly this realization took several months in an A.I. class before I was sufficiently crestfallen. A.I. patterns including the hill climbing algorithm used here are indeed &amp;ldquo;intelligent&amp;rdquo; but really it a reflecting of the algorithm designer, not the entity executing the algorithm. So I built a substitution cipher solver in C++. It&amp;rsquo;s fast it uses random numbers i.e. non-deterministic, it uses an A.I. algorithm i.e. Intelligent, it uses threads i.e. Massively, it deciphers i.e. luminates the text and it solves super stuff therefore the title is completely justified. I give you my Massively Intelligent Non-Deterministic Luminating Effortless Super Solver (MINDLESS). If none of that interests you then please stick around and follow the side quest of looking for &lt;a href=&#34;http://justenoughcraig.blogspot.com/2014/01/just-say-no-to-passive-aggressive.html&#34;&gt;emotionally charged parenthesis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cracking substitution ciphers were a fun puzzle I pursued as a child. Substitution ciphers are monoalphabetic ciphers. Meaning a single letter maps to a single letter and that mapping is static. This is opposed to polyalphabetic ciphers where the mapping of letters changes throughout the message. Vigenère Cipher is an example. Given a substitution cipher what are tools are available to the &amp;ldquo;cryptanalyst&amp;rdquo; (the person to breaks ciphers). Firstly, frequency analysis. Frequency analysis supposes the the distribution of letters within the message is essentially the same as the distribution of letters in the English language (&lt;a href=&#34;http://en.wikipedia.org/wiki/Frequency_analysis&#34;&gt;http://en.wikipedia.org/wiki/Frequency_analysis&lt;/a&gt;). However if the message is short, or if the message is intentionally written to skew the letter distribution this technique is difficult. This post looks at a different approach, an artificial intelligence technique called hill climbing.&lt;/p&gt;

&lt;p&gt;Hill Climbing is simply a search technique that uses a &amp;ldquo;fitness&amp;rdquo; measurement (fancy word for number or quality) to determine if the current search path is a useful one.&lt;/p&gt;

&lt;p&gt;First step in building the substitution solver is to assemble some functions that will perform the substitution. I love the string functions in Python to I ported str.translate() to a form useful for my needs
&lt;pre lang=&#34;cpp&#34; escaped=&#34;true&#34;&gt;std::string translate( cost std::string &amp;amp; str, const std::string &amp;amp; table)
{
    std::string s(str);
    std::string::size_type len = str.size();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if ( table.size() != 256 )
{
    throw std::runtime_error(&amp;quot;Improper table size. Size must be 256 chars&amp;quot;);
}

for ( std::string::size_type i = 0; i &amp;amp;lt; len; ++i )
{
    s[i] = table[ s[i] ];
}
return s;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;std::string maketrans(std::string key)
{
    char t1data[256];
    std::iota(std::begin(t1data), std::end(t1data), 0);
    size_t i = &amp;lsquo;A&amp;rsquo;;
    size_t d = &amp;lsquo;a&amp;rsquo; - &amp;lsquo;A&amp;rsquo;;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for(auto k = std::begin(key); k != std::end(key); ++i, ++k)
{
    t1data[i] = *k;
    t1data[i+d] = std::tolower(*k);
}
return std::string(t1data, 256);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/pre&gt;
This leverages the fact that in C/C++, characters are simply numbers in ascii. Given a key, we can translate any text:
&lt;pre lang=&#34;cpp&#34; escaped=&#34;true&#34;&gt;std::string substitute(std::string text, std::string key)
{
    auto t1 = pystring::maketrans(key);
    return pystring::translate(text, t1);
}&lt;/pre&gt;
Now we need a fitness measurement. Ngrams are a useful tool here. Ngrams are partial words, and since we are more likely to find partial words in our search than full words, we need to give the program a mechanism for measuring this. This &lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2014/02/quadgrams.7z&#34;&gt;ngram&lt;/a&gt; database is a list of quadgrams and their relative frequency in the English language.&lt;/p&gt;

&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;#include &lt;map&gt;
#include &lt;istream&gt;
#include &lt;string&gt;
#include &lt;ctgmath&gt;
#include &lt;iostream&gt;
struct ngram_score 
{
    struct ngram_datum {
        int freq;
        double weight;
    };
    std::map&lt;std::string, ngram_datum&gt; ngrams;
    double floor;
    size_t l;
    size_t n{0};
    ngram_score(std::istream&amp; in)
    {
        std::string line;
        while(in)
        {
            std::string ngram;
            int freq;
            in &gt;&gt; ngram;
            in &gt;&gt; freq;
            ngrams[ngram].freq = freq;
            n += freq;
        }

        for(auto&amp; i : ngrams)
        {
            i.second.weight = std::log10((double)(i.second.freq)/n);
        }
        floor = std::log10(0.01/n);
        l = 4; //for quadgrams.
    }

    double score(std::string text)
    {
        double score{0};
        auto c = std::begin(text);
        auto e = std::end(text);
        for(; c+l-1 != e; ++c)
        {
            //Get a string of correct length
            std::string ngram(c, c+l);
            auto it=ngrams.find(ngram);
            if(it != ngrams.end())
                score += it-&gt;second.weight;
            else
                score += floor;
        }
        return score;
    }
};&lt;/pre&gt;

&lt;p&gt;We can use this as a scorer for a length of text.
&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;std::ifstream fin(&amp;ldquo;../quadgrams.txt&amp;rdquo;);
ngram_score fitness(fin);
auto score = fitness.score(plaintext);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;We now have a substitution tool to make substitutions, and we have a numerical way of measuring the resultant quality. Next is to implement the search, this is the mystical artificial intelligence in the program.
&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;
struct cipher {
    std::string key;
    double score;
    std::string plaintext;
    friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; os, cipher const &amp;amp; c);
};&lt;/p&gt;

&lt;p&gt;cipher break_substitution(std::string cipher_text, std::string skey)
{
    std::transform(std::begin(cipher_text), std::end(cipher_text), std::begin(cipher_text), ::toupper);
    std::uniform_int_distribution&lt;int&gt; distribution(0,25);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cipher p;
p.key = skey;
p.plaintext = substitute(cipher_text, p.key);
p.score = fitness.score(p.plaintext); 
for(size_t i = 0; i &amp;lt; 1000; ++i) //Look at that intelligent for loop
{
    cipher c(p);
    auto a = distribution(g);
    auto b = distribution(g);
    std::iter_swap(std::begin(c.key)+a, std::begin(c.key)+b); //randomly tweak our key
    c.plaintext = substitute(cipher_text, c.key);
    c.score = fitness.score(c.plaintext);  //Measure the quality of the new key.
    if(c.score &amp;gt; p.score)
    {
        p = c; //update the parent
        i = 0; //We&#39;ve made an improvement
    }
}
return p;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;So artificial intelligence, it&amp;rsquo;s just computation.  The trick is that we are a little more intelligent that brute force.  Our algorithm is to generate a random key, substitute the cipher text with that key and measure the quality of the result, i.e., how many partial words are in the result.  Now swap 2 characters, and measure it again. If the result is better continue swapping with that key, if the result is worse throw away that key (branch of the search tree), and return to the previous key (p in this example).&lt;/p&gt;

&lt;p&gt;In this post we looked at how MINDLESS can break substitution ciphers using hill climbing.  If you were following the side-quest, I hope you enjoyed yourself (or rather are overwhelming cross (because of the parenthesis), but be thankful they are balanced).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sean Parent: No Raw Loops</title>
      <link>http://codestrokes.com/2013/11/sean-parent-no-raw-loops/</link>
      <pubDate>Sun, 24 Nov 2013 22:14:50 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/11/sean-parent-no-raw-loops/</guid>
      <description>&lt;p&gt;A group of colleagues and I watched Sean Parent&amp;rsquo;s Going Native Talk on &amp;ldquo;&lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning&#34;&gt;C++ Seasoning&lt;/a&gt;&amp;rdquo;. Parent takes some extreme views on how to use C++, but his examples for using the STL to simplify code are phenomenal. For a recent AI project I decided to apply Parent&amp;rsquo;s &lt;em&gt;goal&lt;/em&gt; of &amp;ldquo;no raw loops&amp;rdquo;, I was blown away by the transformation&amp;hellip; err std::transformation this had on my code. In this post I indented to demonstrate several complex code blocks, or overly specific code blocks what were replaced by some STL magic. Alexander Stepanov says, &amp;ldquo;&lt;a href=&#34;http://www.youtube.com/watch?v=COuHLky7E2Q&#34;&gt;&amp;hellip;code is a liability.&lt;/a&gt;&amp;rdquo; The more code a program has the more likely it contains bugs. The fewer lines of code, the lesser the opportunity for a bug. I haven&amp;rsquo;t quiet decided if I agree with this point, but it does induce thought either way. Sean Parent&amp;rsquo;s methodology seems to agree, for the purposes of this post we&amp;rsquo;ll agree as well.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;So the assignment statement:&lt;/p&gt;

&lt;blockquote&gt;Suppose that you have purchased a bag of candy which has two flavor: cherry (c) and lime (l). We do not know exactly what kind of bag we bought, but we know that it is one of the following types:

&gt; 
&gt; 
    
&gt;   1. 100% cherry (10% likely)
&gt; 
    
&gt;   2. 75% cherry (20% likely)
&gt; 
    
&gt;   3. 50% cherry (40% likely)
&gt; 
    
&gt;   4. 25% cherry (20% likely)
&gt; 
    
&gt;   5. 0% cherry (10% likely)
&gt; 

You take 11 pieces of candy, all happen to be lime. What bag do you most likely have, and what is the probability the next candy will be a lime?&lt;/blockquote&gt;

&lt;p&gt;So lets start with encoding our data.  First we have 2 types of candy: cherry and lime.  Lets represent that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class lime_type{};
class cherry_type{};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We might expand this later, but for now we just need a way to overload functions on lime candies or cherry candies. This will work just fine.&lt;/p&gt;

&lt;p&gt;Next we have some bags, and associated probabilities&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;enum Bag {
Bag1 =1,
Bag2,
Bag3,
Bag4,
Bag5};

std::vector&amp;lt;Bag&amp;gt; const bags{Bag1, Bag2, Bag3, Bag4, Bag5};

map&amp;lt;Bag, double&amp;gt; apriori{
{Bag1, 0.1},
{Bag2, 0.2},
{Bag3, 0.4},
{Bag4, 0.2},
{Bag5, 0.1}
};

map&amp;lt;Bag, std::pair&amp;lt;double, double&amp;gt;&amp;gt; candy_dist{
{Bag1, {1.00, 0.00}},
{Bag2, {0.75, 0.25}},
{Bag3, {0.50, 0.50}},
{Bag4, {0.25, 0.75}},
{Bag5, {0.00, 1.00}}
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, pretty straight forward, but the magic is about to happen&amp;hellip;&lt;/p&gt;

&lt;p&gt;Next we have to consume data from a file. Each data set is represented by a series of l or c on a single line. We need to print a graph for each line.  Our example data file looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jwright@jwright-LinuxAwesome:~/workspaces/school/cse471/hw15$ cat data1.txt
l l
l l l l l l l l l l l l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for our first STL use case. (Actually Boost here, since gcc 4.7.1 doesn&amp;rsquo;t support regex yet, but this functionality will work in gcc 4.9.1).&lt;/p&gt;

&lt;p&gt;The before:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;std::ifstream fin(filename);
    string line;
    while(fin &amp;gt;&amp;gt; line)
    {
        if(line == &amp;quot;l&amp;quot;)
            cout &amp;lt;&amp;lt; &amp;quot;Lime&amp;quot; &amp;lt;&amp;lt; endl;
        if(line == &amp;quot;c&amp;quot;)
            cout &amp;lt;&amp;lt; &amp;quot;cherry&amp;quot; &amp;lt;&amp;lt; endl;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What&amp;rsquo;s wrong with this code block? Consider if our ls and cs aren&amp;rsquo;t white space delimited. Sensor data is noisy/messy all the time. It would be prudent to deal with this case. This code doesn&amp;rsquo;t block on newlines, and streams all the newlines together. We could wrap this code block with a std::getline() loop, but that&amp;rsquo;s going the wrong direction. No raw loops&amp;hellip; What does the STL provide to deal with this? Essentially we want to tokenize each line with _c_s or _l_s as tokens.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;boost::regex reg(&amp;quot;c|l&amp;quot;); //Construct the regular expression here, since it&#39;s expensive
while(std::getline(fin,line))
{ 
    boost::sregex_token_iterator pos(begin(line), end(line), reg);
    boost::sregex_token_iterator end;
    std::for_each(pos, end, [](boost::sregex_token_iterator tok)
    {
        process(tok-&amp;gt;str());
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code isn&amp;rsquo;t directly shorter, but it is certainly more robust. We can deal with extra noise in our data file, and the regex will skip over it gracefully calling our process function once for each l and c it finds on each line.&lt;/p&gt;

&lt;p&gt;Now that we&amp;rsquo;re warmed up, lets check out some better examples. Conditional probabilities have lots of summations, and product chains in them. My initial hack unrolled all these summations. This is both verbose, which can hide errors, but if we can reduce the number of lines we will increase our reliability. First up.&lt;/p&gt;

&lt;p&gt;$$ P( Candy = Lime | Data) = \Sigma_{Bags}(P(lime, Bag_i | Data) $$&lt;/p&gt;

&lt;p&gt;My first hack, looks like something that congealed in a gutter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(cherry_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag3)*p(Bag4, data_type()) +
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This version is has the sad property that a C programmer might say, &amp;ldquo;Awesome, he unrolled the loops. That code will be fast.&amp;rdquo; Stephan T. Lavavej says , &amp;ldquo;&lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler&#34;&gt;Don&amp;rsquo;t help the compiler&lt;/a&gt;&amp;rdquo;. I agree. -funroll-loops will unroll the loops much better than I can.In fact this code as a bug in it. See it?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(cherry_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag3)*p(Bag4, data_type()) + //Boom, check out that hot copy-paste error.
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Corrected, but still not &amp;ldquo;correct&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(lime_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag4)*p(Bag4, data_type()) + //Boom, check out that hot copy-paste error.
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Beside being verbose, and prone to error. It isn&amp;rsquo;t generate. If we grow our dataset, the loop is not wrong. Can we be sure that we&amp;rsquo;ll find every unrolled loop, and fix it? We can do better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(lime_type, data_type)
{
    //
    // \sigma_bags(p(lime, Bag_i | data))
    //   
    std::vector&amp;lt;double&amp;gt; partials(bags.size());
    std::transform(begin(bags), end(bags), begin(partials), [](Bag b){ return p(lime_type(), b)*p(b, data_type()); });
    double a = std::accumulate(begin(partials), end(partials), 0.0 ); //Gotcha 0.0 instead of 0. 0 will cast the result to an int
    return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This version is shorter. The compiler is free to optimize the STL algorithms as needed even unrolling the loops if the compiler deems it will improve the code. This code is readable, but futhermore we can explain this code to a mathematician. Stroustroup says, &amp;ldquo;Express abstracts as the expert in the field does.&amp;rdquo; This function does exactly that. The first step is to compute partial products of $$ P( Lime, Bag_i) * P(Bag_i | Data) $$. Then add the products together. We are agnostic to the number of bags.&lt;/p&gt;

&lt;p&gt;Next what about debugging. I&amp;rsquo;m searching for a bug, and sometimes print statements are the best way to work it out. Lets print out a vector.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector prob;
//...
cout &amp;lt;&amp;lt; &amp;quot;{&amp;quot;;
for(auto&amp;amp; p : prob)
    cout &amp;lt;&amp;lt; p &amp;lt;&amp;lt; &amp;quot;, &amp;quot;;
cout &amp;lt;&amp;lt; &amp;quot;}&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This cannot be bad right? We used the new, shiny range-based for. What can one complain about.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector prob;
//...
cout &amp;lt;&amp;lt; &amp;quot;{&amp;quot;;
std::copy(std::begin(prob), std::end(prob), std::ostream_iterator&amp;lt;double&amp;gt;(cout, &amp;quot;, &amp;quot;));
cout &amp;lt;&amp;lt; &amp;quot;}&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However we can do &lt;a href=&#34;https://github.com/louisdx/cxx-prettyprint&#34;&gt;even better&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include 
cout &amp;lt;&amp;lt; prob;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even though this program was small, the opportunity to improve quality, and robustness, is ever present. C++ is a growing language, and it&amp;rsquo;s new capabilities are really improving the corner cases in software. One key tool in doing so is learning the STL.  I encourage you to study the STL.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>rand() Considered Harmful</title>
      <link>http://codestrokes.com/2013/11/rand-considered-harmful/</link>
      <pubDate>Sun, 17 Nov 2013 16:54:19 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/11/rand-considered-harmful/</guid>
      <description>&lt;p&gt;Stephan T Lavavej (STL) is a tactical speaker. In a short amount of time he convey&amp;rsquo;s essential accurate information which is immediately applicable. In this talk at Going Native 2013, STL takes 20 minutes to teach us how to properly use random numbers in our programs: &lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful&#34;&gt;http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Simplicity Does Matter!</title>
      <link>http://codestrokes.com/2013/11/simplicity-does-matter/</link>
      <pubDate>Tue, 12 Nov 2013 05:56:28 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/11/simplicity-does-matter/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m been sitting this draft for too long, but before I started my research experiment with Haskell I was looking for a language. I was approaching an AI class for my graduate work, and thought I&amp;rsquo;d learn Lisp, or at least &lt;em&gt;a&lt;/em&gt; lisp.  &lt;a href=&#34;http://clojure.org/&#34;&gt;Clojure &lt;/a&gt;was hot, and new (read shiny), so I dove into learning about it&amp;rsquo;s virtues. It&amp;rsquo;s virtues are embodied in its creator, Rich Hickey, who while being a great programmer is a fantastic speaker. The first talk I watched from him, &amp;ldquo;&lt;a href=&#34;http://www.infoq.com/presentations/Are-We-There-Yet-Rich-Hickey&#34;&gt;Are We There Yet?&lt;/a&gt;&amp;rdquo; which is a deep philosophical approach to parallelism.  I in 2012, Rich Hickey was invited to speak at RubyCon, and he gave a fantastic talk titles, &amp;ldquo;&lt;a href=&#34;http://www.youtube.com/watch?v=rI8tNMsozo0&#34;&gt;Simplicity Matters&lt;/a&gt;&amp;rdquo;. Absolutely fantastic! Eventually, I made my way into Haskell, largely by a comment from Andrei Alexandresku, &amp;ldquo;&lt;a href=&#34;http://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Andrei-Alexandrescu-Systematic-Error-Handling-in-C&#34;&gt;Haskell, the language everyone wishes they know.&lt;/a&gt;&amp;rdquo; Rich Hickey&amp;rsquo;s words however remain in each line of code I write, Do not complect, simplicity matters.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Thunk on Laziness</title>
      <link>http://codestrokes.com/2013/10/a-thunk-on-laziness/</link>
      <pubDate>Sun, 27 Oct 2013 23:00:17 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/10/a-thunk-on-laziness/</guid>
      <description>&lt;p&gt;I originally approached Haskell excited, and wide-eyed mystified by the type theory. Type became my golden hammer. In my C programs I typedef&amp;rsquo;d everything so it&amp;rsquo;d have a &amp;ldquo;unique&amp;rdquo; type. I was cautious with my casting. I was hooked. I had an intuitive understanding of laziness, as implemented by Haskell, that would allow one to write&amp;rdquo;streaming&amp;rdquo; algorithms. That is programs that deal with data in an online way to process data as it streams through. While that maybe true, you know what else can do that? C.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
I recently has a problem to extract logs from a product at work. The existing solution e.g. the solution I wrote the week before, was exponential in time. We had a problem. We had to extract the logs, and separate them by an sentinel in the file, encrypt the files, compress them, then copy the output to a thumbdrive. The only problem we didn&amp;rsquo;t have enough RAM to store the entire file in memory, and we didn&amp;rsquo;t have enough flash to create temporary files.  I needed a streaming algorithm.&lt;/p&gt;

&lt;p&gt;My first approach was to use UNIX pipes and filter data through sed | gzip | openssl. This worked, but required multiple workarounds to generate the sed expressions, eventually resulting in exponential time.  The second time, I was discussing with my co-worker, the virtues of compiled code versus shell scripts. In that vain I started looking into openssl as a library rather than an executable. You know who has streaming algorithms? OpenSSL. OpenSSL, has a fantastic abstraction called BIO_, Basic Input/Output. Which are simply functions you connect together in a chain to process data. The BIO interface is designed to allow one to work with SSL encrypted sockets in an intuitive way. For our use case we simply connected an zlib BIO -&amp;gt; AES BIO -&amp;gt; file sink. Write to the zlib, and watch the data compress, and write to the thumbdrive in one swoop, no laziness, thunking, or fancy data structure fusion required. The result: linear time.&lt;/p&gt;

&lt;p&gt;So the lesson here isn&amp;rsquo;t a technological one, but a personal one about myself. Don&amp;rsquo;t reach for a new technology to solve something. Look deeper into the root of the problem, and even a language as &amp;ldquo;dumb&amp;rdquo; and &amp;ldquo;simple&amp;rdquo;, and &amp;ldquo;old&amp;rdquo; as C, can provide the fastest, optimal solution.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Idiomatic Learning</title>
      <link>http://codestrokes.com/2013/10/idiomatic-learning/</link>
      <pubDate>Sun, 20 Oct 2013 23:00:00 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/10/idiomatic-learning/</guid>
      <description>&lt;p&gt;When learning a new language I find it helpful to study a languages idioms. Idioms exist in a language for a specific reason. Sometimes that reason is to further the principles of the language, other times it’s to mask, or otherwise deal with some underlying design decision of the language. Currently, I am studying Haskell, and currently I am struggle to clarify the idioms of the language. The syntax is still very new and awkward, currently with a total authoring in Haskell of 713 lines.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Python has some interesting idioms, but the one that really helped me when learning was “..tuples should have trailing commas…” At that time, the only other language I knew was C, and PIC Assembly. I was very much a hardware engineer, and Python, for me, was a step out of that hardware-centric mindset. So with such a staunch, inflexible background as this, such an idiom felt, dirty and wrong? My first reaction to this was, “What? Really? Why, are python programmers too lazy?” At first I refused to do this, claiming that my source code was more elegant, and clean. However some time later I learned the second part of this idiom, “…tuples should have trailing commas, BECAUSE syntactically the comma creates the tuple, not the parenthesizes.” Whoa! What an epiphany. From this simple clause, I can now create a tuple with 1 element! The because clause of an idiom, really opens doors in your mind. It really clarifies some subtle point, or characteristic of the language.&lt;/p&gt;

&lt;p&gt;C++ on the other hand has a number of idioms that have become quite ingrained that it&amp;rsquo;s hard to separate, &amp;ldquo;yeah that&amp;rsquo;s just C++ syntax&amp;rdquo;, from, &amp;ldquo;That&amp;rsquo;s just how I do it,&amp;rdquo; to, &amp;ldquo;Oh yeah, I guess template &lt;typename T&gt; class &amp;hellip; isn&amp;rsquo;t very intuitive is it.&amp;rdquo; C++ is a complex multi-paradigm language with one sweeping design decision: You pay for what you use. For instance, take class methods. In C++ class methods are not polymorphic by default. I remember as a fledgling C++ programmer asking my computer science friend, Brian, &amp;ldquo;&amp;hellip;classes are useless without polymorphism. That&amp;rsquo;s just stupid.&amp;rdquo; He tried to explain it to me, but I was probably to frustrated to understand. What I didn&amp;rsquo;t know was the because, and I continued my ignorant use of virtual until I read &lt;a href=&#34;http://www.amazon.com/gp/product/0201543303/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0201543303&amp;amp;linkCode=as2&amp;amp;tag=codestro-20&#34;&gt;The Design and Evolution of C++&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=codestro-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=0201543303&#34; alt=&#34;&#34; /&gt;
 that I learned the reason. Polymorphism requires a level of indirection to implement. Doing so affects performance. C++ doesn&amp;rsquo;t push this on you unless you want it, just non-polymorphic by default, virtual if you want. Beautiful. Now as an embedded system designer I love this aspect of C++. I am free to use the features I need without paying for the ones I don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;So now as I approach Haskell, I read blogs, and statements with a temporary suspension of judgement until I learn the because.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#34;Smaller&#34; Reviews are More Effective</title>
      <link>http://codestrokes.com/2013/10/smaller-reviews-are-more-effective/</link>
      <pubDate>Sun, 13 Oct 2013 23:00:23 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/10/smaller-reviews-are-more-effective/</guid>
      <description>&lt;p&gt;I was reviewing a new software module for work today, and discovered that when the class fit on a single screen my comments were more meaningful, than when the class was larger.  My comments for spatially larger classes were mostly focused on syntactic, and idiomatic details. It was an interesting self-observation, but this certainly isn&amp;rsquo;t new information.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;I&amp;rsquo;ve heard the adage that smaller reviews are more effective than larger ones. At a conference I attended hosted by Atlassian: The JIRA team noted several instances where the time per file decreased with the number of files in the review. This is an interesting observation, and certainly is intuitive thinking about corporate programming and the culture that invites. However, I think of this metric as the extra-dependency size. Where extra is the logical dependency between components of the different files. This is translatable to the system review, and I feel code is the wrong place to be finding system bugs.&lt;/p&gt;

&lt;p&gt;Instead code reviews are supposed to look at the coding faults introduced by the coder themselves. I there there should be a new metric I&amp;rsquo;m calling the &amp;ldquo;inter-dependency&amp;rdquo; size. It is the worst case distance (In number of lines) between a bug, and its inputs. For instance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int add(int a, int b) const
 {
 return a - b;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This snippet has an inter-dependency size of 2. The function call brings in the inputs, to the computation performed on those inputs. This is much easier to catch in practice than a very large function with lots of mutation. When I setup a review for my own code, I relish, even dare my co-workers to find errors. It saves me a lot of trouble to find the bug now, instead of the night of my daughter&amp;rsquo;s ballet recital. I define revies as a process to maximize the probability my team will find mistakes. I then posit to design my reviews with as much care as I design the code itself, and minimize the inter-dependency size for my functions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Itanium Flop</title>
      <link>http://codestrokes.com/2013/10/the-itanium-flop/</link>
      <pubDate>Mon, 07 Oct 2013 01:23:13 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/10/the-itanium-flop/</guid>
      <description>&lt;p&gt;I wake up in the morning with ideas that please me, and some of those ideas actually please me also later in the day when I&amp;rsquo;ve entered them into my computer. - Donald Knuth&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m on a bit of a Knuth kick right now, and I&amp;rsquo;ve been procrastinating studying, and homework to find interviews, and papers by the master himself. I currently have a list of microfiche references to check out as soon as I get to the basement of my university&amp;rsquo;s library: Woot, &lt;a href=&#34;http://www.chrisfenton.com/homebrew-cray-1a/&#34;&gt;computational necromancy&lt;/a&gt;! Through this, I came across a quote in an &lt;a href=&#34;http://www.informit.com/articles/article.aspx?p=1193856&#34;&gt;interview&lt;/a&gt;, &amp;ldquo;&amp;hellip;worse than the &amp;ldquo;&lt;a href=&#34;http://en.wikipedia.org/wiki/Itanium&#34;&gt;Itanium&lt;/a&gt;&amp;rdquo; approach that was supposed to be so terrific—until it turned out that the wished-for compilers were basically impossible to write.&amp;rdquo; What? I thought it was simply market forces that drive the x86-64 ahead of Itanium: nope!&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;a href=&#34;https://www.usenix.org/legacy/event/usenix05/tech/general/gray/gray.pdf&#34;&gt;This&lt;/a&gt; paper discusses some of the advanced features of the Itanium platform as well as Intel&amp;rsquo;s intention for those features. Essentially, the Itanium platform is about empowering software developers. The CPU even provides a &amp;ldquo;software TLB&amp;rdquo;. In a typical software application performance is dependent on the CPU&amp;rsquo;s ability to pipeline, and reorder instructions. This is typically done in hardware. While this approach has proven workable, Intel notes the limitations of &amp;ldquo;speculation&amp;rdquo; by the hardware. The thought then arises, why not turn the advanced speculation functions over to the compiler writer. Itanium is born. Gray discusses how these functions while advanced leaves a huge responsibility on the already loaded optimized running in the compiler. The paper, is a great read, and as Knuth alludes, a similar situation is happening with multi-core today.&lt;/p&gt;

&lt;p&gt;Hardware designers have hit physical limits with clock speeds, just as they hit speculation limits almost a decade before. The hardware engineers are pushing the onus of performance to software once again. Are we ready to carry the torch this time?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux User&#39;s Group CTF 2013</title>
      <link>http://codestrokes.com/2013/09/linux-users-group-ctf-2013/</link>
      <pubDate>Sun, 08 Sep 2013 21:58:06 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/09/linux-users-group-ctf-2013/</guid>
      <description>&lt;p&gt;This past weekend we held another capture the flag event at the Arizona State University&amp;rsquo;s Linux User&amp;rsquo;s Group. It had more of a system admin focus than security cracking exploits, but it was fun an nontheless a diverse learning experience for all those involved. However, almost immediately, I realized the number one rule in CTF, nothing is off limits!
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
The game was organized into two parts, a game server which collected the the scores and displayed the point totals of all teams in real-time, and the virtual servers (hosted on Amazon EC2) which contained the actual games. Players were encouraged to break into teams, and register themselves on the game server. The game server would assign the team a virtual machine, and the team could log in via SSH to behind hacking. Five minutes into the registration process, one team attempted a SQL injection attack against the game server.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_1189&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;700&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2013/09/Final-Score.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2013/09/Final-Score-1024x429.png&#34; alt=&#34;Notice the SQL Injection attempt&#34; /&gt;
&lt;/a&gt; Notice the SQL Injection attempt[/caption]&lt;/p&gt;

&lt;p&gt;I wrote the game server as a django webapp, to collect points, and serve as a dashboard for the players. We logged in at the front of the room and displayed the graph on the front projector. It was a very motivating aspect of the game, however I never planned on it being part of the game itself.  First lesson learned in capture the flag, nothing is off limits. Luckily, django does the right thing, and sanitizes form data automatically. The server was unscathed, the failed injection attempt was displayed for all the teams to see. I&amp;rsquo;m currently compiling additional aspects of what worked and what didn&amp;rsquo;t so check back soon. The CTF was a fantastic event this year, and really motivated newbies, and elites a like.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
