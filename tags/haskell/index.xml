<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Haskell on Code Strokes</title>
    <link>https://codestrokes.com/tags/haskell/</link>
    <description>Recent content in Haskell on Code Strokes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 20 Oct 2013 23:00:00 +0000</lastBuildDate>
    <atom:link href="https://codestrokes.com/tags/haskell/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Idiomatic Learning</title>
      <link>https://codestrokes.com/2013/10/idiomatic-learning/</link>
      <pubDate>Sun, 20 Oct 2013 23:00:00 +0000</pubDate>
      
      <guid>https://codestrokes.com/2013/10/idiomatic-learning/</guid>
      <description>&lt;p&gt;When learning a new language I find it helpful to study a languages idioms. Idioms exist in a language for a specific reason. Sometimes that reason is to further the principles of the language, other times it’s to mask, or otherwise deal with some underlying design decision of the language. Currently, I am studying Haskell, and currently I am struggle to clarify the idioms of the language. The syntax is still very new and awkward, currently with a total authoring in Haskell of 713 lines.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Python has some interesting idioms, but the one that really helped me when learning was “..tuples should have trailing commas…” At that time, the only other language I knew was C, and PIC Assembly. I was very much a hardware engineer, and Python, for me, was a step out of that hardware-centric mindset. So with such a staunch, inflexible background as this, such an idiom felt, dirty and wrong? My first reaction to this was, “What? Really? Why, are python programmers too lazy?” At first I refused to do this, claiming that my source code was more elegant, and clean. However some time later I learned the second part of this idiom, “…tuples should have trailing commas, BECAUSE syntactically the comma creates the tuple, not the parenthesizes.” Whoa! What an epiphany. From this simple clause, I can now create a tuple with 1 element! The because clause of an idiom, really opens doors in your mind. It really clarifies some subtle point, or characteristic of the language.&lt;/p&gt;

&lt;p&gt;C++ on the other hand has a number of idioms that have become quite ingrained that it&amp;rsquo;s hard to separate, &amp;ldquo;yeah that&amp;rsquo;s just C++ syntax&amp;rdquo;, from, &amp;ldquo;That&amp;rsquo;s just how I do it,&amp;rdquo; to, &amp;ldquo;Oh yeah, I guess template &lt;typename T&gt; class &amp;hellip; isn&amp;rsquo;t very intuitive is it.&amp;rdquo; C++ is a complex multi-paradigm language with one sweeping design decision: You pay for what you use. For instance, take class methods. In C++ class methods are not polymorphic by default. I remember as a fledgling C++ programmer asking my computer science friend, Brian, &amp;ldquo;&amp;hellip;classes are useless without polymorphism. That&amp;rsquo;s just stupid.&amp;rdquo; He tried to explain it to me, but I was probably to frustrated to understand. What I didn&amp;rsquo;t know was the because, and I continued my ignorant use of virtual until I read &lt;a href=&#34;http://www.amazon.com/gp/product/0201543303/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0201543303&amp;amp;linkCode=as2&amp;amp;tag=codestro-20&#34;&gt;The Design and Evolution of C++&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=codestro-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=0201543303&#34; alt=&#34;&#34; /&gt;
 that I learned the reason. Polymorphism requires a level of indirection to implement. Doing so affects performance. C++ doesn&amp;rsquo;t push this on you unless you want it, just non-polymorphic by default, virtual if you want. Beautiful. Now as an embedded system designer I love this aspect of C++. I am free to use the features I need without paying for the ones I don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;So now as I approach Haskell, I read blogs, and statements with a temporary suspension of judgement until I learn the because.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interesting article about Monads</title>
      <link>https://codestrokes.com/2013/08/interesting-article-about-monads/</link>
      <pubDate>Fri, 02 Aug 2013 22:49:01 +0000</pubDate>
      
      <guid>https://codestrokes.com/2013/08/interesting-article-about-monads/</guid>
      <description>&lt;p&gt;I found an interesting blog today with some clear and interesting discussion on Haskell, and Monads: &lt;a href=&#34;http://intoverflow.wordpress.com/2010/07/20/i-come-from-java-and-want-to-know-what-monads-are-in-haskell/&#34;&gt;http://intoverflow.wordpress.com/2010/07/20/i-come-from-java-and-want-to-know-what-monads-are-in-haskell/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My Haskell Environment for Project Euler</title>
      <link>https://codestrokes.com/2013/08/my-haskell-environment-for-project-euler/</link>
      <pubDate>Fri, 02 Aug 2013 16:51:40 +0000</pubDate>
      
      <guid>https://codestrokes.com/2013/08/my-haskell-environment-for-project-euler/</guid>
      <description>&lt;p&gt;For the last several months I&amp;rsquo;ve been working on Project Euler in Haskell. My intent has been to learn Haskell, and grasp the functional concepts. While working on several problems it&amp;rsquo;s important to have a workflow that allows for a fast cycle time. I spent some time with Cabal, attempting to build a scheme that works efficiently, but was unable to do so. Instead I setup a mix of cabal-dev, and make to build a fast workflow that allow for compiling, testing, common code libraries, and benchmarks. This post is a walk though of that workflow. &amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
My most important requirements is cycle time. I a minimum edit-compile-test/execute cycle. This helps me to clearly and quickly work on problems. Especially in compiled languages with libraries, and common code, it is important that a single code change is a single file recompiles a minimum of effort (&lt;a href=&#34;http://www.joelonsoftware.com/articles/fog0000000043.html&#34;&gt;Joel Spoksky&lt;/a&gt;). Therefore my Makefile must describe the dependencies, which themselves are dynamic as the code base grows and changes. Cabal supposedly does this, but Project Euler is uniquely outside the framework offered by cabal. In Project Euler, each solution is a single executable. The project itself is many executables. Maintaining a cabal files for that many executables does not meet my desire for dynamically managed dependencies. Instead I favor make; simple &lt;em&gt;make&lt;/em&gt;. Therefore the requirements of my project euler environemnt are:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Primary Requirement&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fast Cycle Time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Secondary Requirements&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Testing&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Unit testing is a minimum, but haskell allows test generation which is something I plan to learn and use heavily.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Sandbox Dependencies&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;standard and contributed libraries i.e. libraries not written by me should not clutter the standard library search space e.g. /usr/local/ghc/lib&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Minimal Rebuilt&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I must have a clean and simple test environment to run unit tests on my common modules, as well as any project file&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;I want changing source files, should only rebuild the tests affected by those changes.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Benchmarking&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I must have a dependable and repeatable benchmark for evaluating my code. Project Euler encourages one to complete each solution in 1 minute. Benchmarking is useful to see the common code base improve over time, as well as assert all programs complete in the encouraged time limit.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Profiling&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Profiling is essential, especially in Haskell, since laziness makes space complexity difficult to estimate.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Tertiary Requirements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Background Exploration&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I am using Project Euler as a conduit to learn Haskell. As such, I must be able to explore random ideas in a meaningful way. Those changes should be preserved do I can go back and look at my past attempts.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With these requirements in mind, and 10 Project Euler solutions complete, I set out to design a project environment. It&amp;rsquo;s important that I already had some solutions complete before I started this endeavor. Why? Two reasons: 1 personally, I am prone to analysis-paralysis, in that I will tweak my editor, and build environment to get it &amp;ldquo;perfect&amp;rdquo; before I write any code. This is useless.Secondly, usually, you don&amp;rsquo;t know what you need until you don&amp;rsquo;t have it. By that I mean, 2 or 3 source files, it doesn&amp;rsquo;t really matter how slow or inefficient your compile-test-execute loop is since its only a small environment. The start of time of the compiler is the most significant aspect of this cycle. The dependencies are not complex enough to really demonstrate the effort. However, as the project grows these inefficiencies build, and expand on one another until you realize what&amp;rsquo;s missing. For me that was 10 solutions in.&lt;/p&gt;

&lt;p&gt;At 10 solutions in I found myself trying to break a module into 2 pieces, and discovered the trivial &lt;em&gt;ghc &amp;ndash;make&lt;/em&gt; step I used became less effective. At this point it wasn&amp;rsquo;t really a time efficient, but an irritation. An irritation I knew would grow to zap a significant amount of time. I fix my own irritations as soon as I can in a process I call &lt;a href=&#34;https://summit.atlassian.com/archives/2012/dev-speed/moneypenny-speaks&#34;&gt;Dev-Speed&lt;/a&gt; (a term I stole from the development team at Atlassian). Dev-Speed is the concept that an efficient work environment will make a more efficient engineer, thus higher quality code. Efficiency for me is minimal irritation for common tasks. However, fixing any irritation as it raises it&amp;rsquo;s head will take one back to analysis paralysis and nothing will get done. Thus dev-speed is the process of setting regular intervals for project effort. At the end of the interval I reward myself by fixing some irritation in my cycle. This has the added impact of accelerating my development. When I hit a problem instead of procrastinating by choosing a &amp;ldquo;better&amp;rdquo; font for my editor, I work harder to get to my dev-speed cycle sooner. 10 solutions ended my first cycle. Ah. Now it&amp;rsquo;s time to make it awesome.&lt;/p&gt;

&lt;p&gt;First step is purely mechanical: project structure. Initially I had a flat simple structure with a Makefile and my source files in the same folder. For a few sources this was fine. I know I would out grow this structure, but I choose to not spend any time thinking about a better structure and instead ignored the irritation until my dev-speed cycle. For my folder structure I like to be idiomatic of the language, so I searched: &amp;ldquo;Haskell project folder structure&amp;rdquo; and found (&lt;a href=&#34;http://www.haskell.org/haskellwiki/Structure_of_a_Haskell_project&#34;&gt;http://www.haskell.org/haskellwiki/Structure_of_a_Haskell_project&lt;/a&gt;). I stole the project structure outright.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
├── dist
├── doc
│   ├── Background
│   └── haskell-primes
├── src
│   ├── Data
│   └── Euler
├── testsuite
│   ├── benchmarks
│   └── tests
│   └── Euler
└── util
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I have a clean, usable structure, and a place for everything to go. My requirements now have folders to work within. However there is a problem, I have a place to put &lt;em&gt;my own&lt;/em&gt; libraries, but what about standard libraries and packages for the project. I need sandbox builds. Coming from python, I love virtual environments. Professionally, all our projects are cross-compiled, and we worked out a similar virtual-environment setup for C++/ARM/x86/x86-64. As this is one of my requirements. I searched for Haskell virtual environments and found a project by Galois called cabal-dev, which creates cabal sandboxes. This allows me to list by dependencies locally, and install them locally. Now I can freely install Hackage packages without fear of corrupting other Haskell Projects of my own or on the system. Cleaning a corrupt cabal repository is easier too, just make clean!&lt;/p&gt;

&lt;p&gt;Okay primary requirements are met. Contributed libraries will not clutter my global spaces, and I have a clean efficient folder structure to built my project. Next step is to setup my makefile to build everything. Make is a fantastic tool, really. It doesn&amp;rsquo;t get a lot of direct attention or praise, but it is certainly the master of time based dependency management.&lt;/p&gt;

&lt;blockquote&gt;While tweaking the makefile, _make -d | less_ was massively useful. It prints out the process steps make is executing so you can tune the makefile to only rebuild what&#39; necessary, our see what make believes is missing.&lt;/blockquote&gt;

&lt;p&gt;It&amp;rsquo;s more than just a source building tool. Since I have common libraries shared among multiple executables I&amp;rsquo;m using ghc&amp;rsquo;s makefile dependency features. (&lt;a href=&#34;http://www.haskell.org/ghc/docs/7.6.2/html/users_guide/separate-compilation.html#makefile-dependencies&#34;&gt;http://www.haskell.org/ghc/docs/7.6.2/html/users_guide/separate-compilation.html#makefile-dependencies&lt;/a&gt;). So lets analyze the dependencies.&lt;/p&gt;

&lt;p&gt;All my source files are in /src. My library code is in /src/Euler. Data Files are in /src/Data. contributed libraries are installed by cabal-dev into /dist. Now as I create new solutions I don&amp;rsquo;t want to edit the makefile to add the new source files. Make should just discover them. This is a wildcard pattern SRCS=$(wildcard src/*.hs) #Define a variable called SRCS, that includes all the .hs files in the src folder.  Now what we need is a mapping from the source files to the executable. Make needs to know what the resulting executable name will be in order to see that it&amp;rsquo;s missing. For example lets say we want to compile /src/001.hs into /src/001. Make will start up and look for /src/001 if it doesn&amp;rsquo;t exist, it will look for a rule that defines how to convert /src/001.hs to /src/001.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;all: $(PROGS)

%: %.hs
    $(HC) $(HC_OPTS) $*.hs
.hs.o:
        $(HC) -c $&amp;lt; $(HC_OPTS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These 2 rules do just that .hs -&amp;gt; .o -&amp;gt; executable (i.e. no extension). Said another way, give me something.hs and I&amp;rsquo;ll return you something.o then give me something .o I&amp;rsquo;ll return you an executable. Make calls these recipes. So we have a variable with a list of the .hs files called SRCS we need a list of the progs -&amp;gt; $(PROGS). Make has a facility for this called pattern substution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PROGS=$(patsubst %.hs,%,$(SRCS))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This line defines a variable that converts all the source files to executable names. In this case it simply drops the .hs extension. On windows one would want to add .exe&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PROGS=$(patsubst %.hs,%.exe,$(SRCS))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a list of the programs, and a list of the sources, but we have a catch. What about the libraries? Who depends on those? It&amp;rsquo;s important that we setup our build such that only the solutions truely dependent on a library function will be rebuilt, otherwise we watse a great deal of time building project which haven;t actually changed. For this case, ghc will generate the dependency rules for us which describe which source files are dependent on which library sources. Additionally, when the dependencies are correct make -j will do the right thing, which can massively improve the build speed. Here&amp;rsquo;s the rule to generate the build dependencies&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;depend: .depend
    @:

.depend: $(SRCS) $(DEP_LIBS)
    ghc -dep-makefile .depend -M $(HC_OPTS) $(SRCS)

-include .depend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ghc will by default append the dependencies to the current Makefile. I personally don&amp;rsquo;t like that. the  dependencies are a generated item, and should therefore not be checked into version control. So I generate a separate file .depend and include it with the -include. -include will not complain if the file doesn&amp;rsquo;t exist, as is the case on a clean build.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_1135&amp;rdquo; align=&amp;ldquo;alignright&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2013/08/euler.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2013/08/euler-300x225.png&#34; alt=&#34;Euler benchmarks up to 037&#34; /&gt;
&lt;/a&gt; Benchmarks generated with octave measuring the current solutions.[/caption]&lt;/p&gt;

&lt;p&gt;Great! Now we have a dependable build system and make -j does the right thing. Next we need benchmarks. Beyond just the project euler guidelines benchmarks are extremely important. From an educational standpoint you have a quantitative item to measure progress, (or lack there of). From a professional point of view, it&amp;rsquo;s always satisfying to display a graph showing your performance is better than someone else. Graphs are how gentlemen insult each other.&lt;/p&gt;

&lt;p&gt;What are we benchmarking? Compile Time, Run Time, and a set of common functions. Compile time is important for comparing against the intrepreted langauges like Python. A runtime spec from Python includes the compile time ostensibly, so it&amp;rsquo;s an interesting point of comparison. The general setup here is a JSON file which maps numbered solutions to the correct answers, a python script to run and time the programs and compare the answer, and lastly an octave script to tie all the data files together into beautiful soul crushing graphs. At the top level are the Makefile rules to execute the recipes in an sensible order.&lt;/p&gt;

&lt;p&gt;I want to type &lt;em&gt;make check&lt;/em&gt; on the command line to verify all programs are correct. This is especially useful when hacking on library code since the changes could break old solutions. This is separate from &lt;em&gt;make test&lt;/em&gt; which runs my unit tests. Make check should output a graph file (eventually) so lets call out the file we want to generate&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;check: euler.png
    @:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;make needs a recipe for euler.png&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;euler.png: dist/times.dat $(BENCH_PROGS)
        testsuite/benchmarks/prime &amp;gt; dist/bench.dat
        octave util/process.m

dist/times.dat: $(PROGS)
    util/EulerValues.py --answers util/answers.js --file dist/times.dat $(PROGS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The euler graph needs runtimes, and the bench programs themselves. times.dat is generated by the python script and depends on the programs. Now each component is built, we can run the benchmark programs and finally octave to output the graph. There is the makefile in it&amp;rsquo;s entirety&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SRCS=$(wildcard src/*.hs)
BENCH_SRCS=$(wildcard testsuite/benchmarks/*.hs)
BENCH_PROGS=$(patsubst %.hs,%,$(BENCH_SRCS))
TEST_SRCS=$(wildcard testsuite/tests/Euler/*.hs)
TEST_PROGS=$(patsubst %.hs,%,$(TEST_SRCS))
LIBS=$(wildcard src/Euler/*.hs)
PROGS=$(patsubst %.hs,%,$(SRCS))
COMPILE_TIMES=dist/compile.dat
HC=ghc
DEP_LIBS=dist/packages-7.6.3.conf
HC_OPTS=-O3 -isrc/ -package-db=$(DEP_LIBS)
GET_TIMESTAMP=$(shell date +%s.%N)
CABAL=$(HOME)/.cabal/bin/cabal-dev

.SUFFIXES: .o .hs .hi .lhs .hc .s

.PHONY: all clean depend test

all: $(PROGS) .depend

%: %.o $(LIBS) $(DEP_LIBS)
    @echo -n &amp;quot;$*.hs\t&amp;quot; &amp;gt;&amp;gt; $(COMPILE_TIMES)
    @echo -n &amp;quot;$(GET_TIMESTAMP)\t&amp;quot; &amp;gt;&amp;gt; $(COMPILE_TIMES)
    $(HC) $(HC_OPTS) $*.hs
    @echo &amp;quot;$(GET_TIMESTAMP)&amp;quot; &amp;gt;&amp;gt; $(COMPILE_TIMES)

$(DEP_LIBS):
    $(CABAL) install -s dist/ digits

check: euler.png
    @:

test: $(TEST_PROGS)
    $(foreach x,$(TEST_PROGS),./$(x)${\n})

bench: $(BENCH_PROGS)
    @:

dist/times.dat: $(PROGS)
    util/EulerValues.py --answers util/answers.js --file dist/times.dat $(PROGS)

euler.png: dist/times.dat $(BENCH_PROGS)
    testsuite/benchmarks/prime &amp;gt; dist/bench.dat
    octave util/process.m

clean: 
    rm -rf $(PROGS) $(BENCH_PROGS) dist/* .depend
    find . -name *.o -exec rm -rf {} \;
    find . -name *.hi -exec rm -rf {} \;

#Standard Suffix Rules
.o.hi: 
    @:

.lhs.o:
    $(HC) -c $&amp;lt; $(HC_OPTS)

.hs.o:
    $(HC) -c $&amp;lt; $(HC_OPTS)

depend: $(SRCS) $(DEP_LIBS)
    ghc -dep-makefile .depend -M $(HC_OPTS) $(SRCS)

-include .depend
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There we have it. A cleanly organized, portable project with minimal rebuild, and a fast edit/build/run cycle! I&amp;rsquo;m always looking for improvements for my next dev-speed cycle. Please comment on any points of improvements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Haskell a Few Problems Later</title>
      <link>https://codestrokes.com/2013/05/haskell-a-few-problems-later/</link>
      <pubDate>Tue, 14 May 2013 04:28:58 +0000</pubDate>
      
      <guid>https://codestrokes.com/2013/05/haskell-a-few-problems-later/</guid>
      <description>&lt;p&gt;Well, the Haskell honeymoon is over for me. I spent some time working on a few Project Euler problems this weekend, and my initial assumptions formed from toy problems were dashed. While I was able to solve 3 problems fairly quickly, I faced a number of non trivial bugs, and memory issues. On the other side of my naïve passion, I’m finding a functional thought process, and it’s exciting.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;My problems were really centered around a naïve belief that Haskell could convert my inefficient algorithms to some &amp;ldquo;mathematically pure&amp;rdquo; representation. I am still learning a great deal about Haskell, and the point remains, low-level memory issues independent of &amp;ldquo;high-level&amp;rdquo; classification are ever present. As I study Haskell, I am beginning to appreciate the syntax. However, my goals for Haskell weren’t ever to use it deeply, but instead to develop my sense of functional design. Enter the python list comprehension. I use python extensively for school, and the latest project I was working on, used Python to implement a Naïve Bayesian Classifier. Essentially, one is supposed to collect all the words in document, collect all the unique words, and select all the words which are not too short or too long. Python’s list comprehensions make this elegant and fast!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; def text_process_all(self, exampleset):
        processed_training_set = [self.text_process_entry(i) for i in self.training_set]
        processed_training_set = filter(lambda x: len(x[0]) &amp;gt; 0, processed_training_set) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Python’s list comprehensions are a function concept that increase the &lt;a href=&#34;http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Python_is_not_C&#34;&gt;performance&lt;/a&gt; of python loops. The benevolent dictator for life wrote a succinct article about &lt;a href=&#34;http://www.python.org/doc/essays/list2str.html&#34;&gt;loop performance in python&lt;/a&gt;. One outcome of this essay is that to make python fast stay inside the C part of python. List comprehensions do just this. Essentially they vectorize an operation and return back up to python once the list is composed. Functional concepts with a performance boost. Awesome.&lt;/p&gt;

&lt;p&gt;[suffusion-adsense client=&amp;lsquo;ca-pub-6284398857369558&amp;rsquo; slot=&amp;lsquo;1495369305&amp;rsquo; width=&amp;lsquo;728&amp;rsquo; height=&amp;lsquo;90&amp;rsquo;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Haskell Day 1 (Again)</title>
      <link>https://codestrokes.com/2013/04/haskell-day-1-again/</link>
      <pubDate>Mon, 22 Apr 2013 05:29:11 +0000</pubDate>
      
      <guid>https://codestrokes.com/2013/04/haskell-day-1-again/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve restarted my haskell programming education. Here is my implementation of &lt;a href=&#34;http://imranontech.com/2007/01/24/using-fizzbuzz-to-find-developers-who-grok-coding/&#34;&gt;FizzBuzz&lt;/a&gt;
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fizzbuzz x | x `mod` 15 == 0 = &amp;quot;FIZZBUZZ&amp;quot;
           | x `mod` 3  == 0 = &amp;quot;FIZZ&amp;quot;
           | x `mod` 5  == 0 = &amp;quot;BUZZ&amp;quot;
           | otherwise       = show x

main = print (map fizzbuzz [1..100])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[suffusion-adsense client=&amp;lsquo;ca-pub-6284398857369558&amp;rsquo; slot=&amp;lsquo;1495369305&amp;rsquo; width=&amp;lsquo;728&amp;rsquo; height=&amp;lsquo;90&amp;rsquo;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Know Its Name</title>
      <link>https://codestrokes.com/2012/07/know-its-name/</link>
      <pubDate>Sat, 21 Jul 2012 19:24:19 +0000</pubDate>
      
      <guid>https://codestrokes.com/2012/07/know-its-name/</guid>
      <description>&lt;p&gt;Programming is at it&amp;rsquo;s heart an struggle in communication. Source code is the communication medium with the processor; Comment the medium to other coders, and UML the medium to higher-level communication. Computer Scientists have the stereotype of being poor communicators, but in our own mediums, we&amp;rsquo;re phenomenal. This fact is no where more apparent, than trying to explain source code to someone else. How does one read source code? I&amp;rsquo;m currently, learning Haskell, and my first goal is to understand this question. How can I read (out loud):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ x * x | x &amp;lt;- nums, x &amp;lt; 7]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;a href=&#34;http://www.haskell.org/haskellwiki/Haskell_Tutorial_for_C_Programmers&#34;&gt;Reference&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;After some searching I found a primer to &lt;a href=&#34;http://stackoverflow.com/questions/7746894/are-there-pronounceable-names-for-common-haskell-operators&#34;&gt;Haskell Vocabulary&lt;/a&gt;. Even at this basic level I see the connection to Mathematics. Therefore I&amp;rsquo;d read this statement as:&lt;/p&gt;

&lt;p&gt;&amp;ldquo;X&amp;rdquo; times &amp;ldquo;X&amp;rdquo;,  Given That, &amp;ldquo;X&amp;rdquo; takes nums, where x is greater-than 7&lt;/p&gt;

&lt;p&gt;One of my favorite quotes about C++ goes like: &amp;ldquo;Except for the syntax, C++ is awesome.&amp;rdquo;.  And in C++ it&amp;rsquo;s even more critical to be able to read source code to someone. Therefore, I post a project to you, study some code you&amp;rsquo;ve written. Then try to read this code to someone else. It will be an interesting, and useful exercise for both of you.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
