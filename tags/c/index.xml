<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>C on Code Strokes</title>
    <link>http://codestrokes.com/tags/c/</link>
    <description>Recent content in C on Code Strokes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Sep 2014 23:00:00 -0700</lastBuildDate>
    <atom:link href="http://codestrokes.com/tags/c/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Property Testing in C&#43;&#43;</title>
      <link>http://codestrokes.com/2014/09/property-testing-in-c/</link>
      <pubDate>Wed, 03 Sep 2014 23:00:00 -0700</pubDate>
      
      <guid>http://codestrokes.com/2014/09/property-testing-in-c/</guid>
      <description>&lt;p&gt;
Currently, I&#39;m on a testing kick. One might say tests are shiny. I don&#39;t
know if they are really shiny as much as I found another cool use for
uniform_int_distribution&lt;&gt;. A use which, as a side effect, might make me
appear to be a better software developer. (This assumes a negative bug rate is
proportional to better software). I&#39;ve started playing with Property Testing.
Property Testing is a form of unit testing where the programmers defines
properties, or invariants about the code. A &lt;del&gt;framework&lt;/del&gt; library (ok,
seriously its a framework because it calls your code) generates random
constrained inputs and calls your test functions. It&#39;s pretty cool, and while
I was playing around with the framework, I found a real bug, related to my
ignorance of C++&#39;s auto type deduction.&lt;/p&gt;&lt;p&gt;Let&#39;s steal a simple
example from my CSE 565 Software Verification class: a payroll function. Here
is the specification:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Design a function that calculates
payroll for an employee.&lt;/p&gt; &lt;h3&gt;Inputs&lt;/h3&gt; &lt;p&gt;Employee Id number&lt;br&gt;Number
of Hours&lt;/p&gt; &lt;h3&gt;Outputs&lt;/h3&gt; &lt;p&gt;Amount to pay employee as a floating point
value.&lt;/p&gt; &lt;h3&gt;Constraints&lt;/h3&gt; &lt;p&gt;Pay is calculated at $10 for standard time,
$15 for overtime over 40 hours.&lt;br&gt;Overtime starts over 40 hours&lt;br&gt;Maximum
number of hours is 100.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;For this demonstration, I’m using
a C++ port of Haskell’s QuickCheck, CppQuickCheck (&lt;a
title=&#34;https://github.com/grogers0/CppQuickCheck&#34;
href=&#34;https://github.com/grogers0/CppQuickCheck&#34;&gt;https://github.com/grogers0/CppQuickCheck&lt;/a&gt;,
my fork and the examples in this post are available here: &lt;a
title=&#34;https://github.com/jwright85/CppQuickCheck&#34;
href=&#34;https://github.com/jwright85/CppQuickCheck&#34;&gt;https://github.com/jwright85/CppQuickCheck&lt;/a&gt;).
QuickCheck was designed by John Hughes who has gone on to support a commercial
version of the library for verifying (and validating) automotive requirements
for Volvo (&lt;a title=&#34;http://vimeo.com/68331689&#34;
href=&#34;http://vimeo.com/68331689&#34;&gt;http://vimeo.com/68331689&lt;/a&gt;).&amp;nbsp; His
presentations have motivated me to try this testing strategy for my own
programs. Lets start with a quick implementation for our payroll function.
We&#39;ll then apply properties against the function until we are satisfied with
the implementation. Although property testing can provide more confidence in
an implementation Dijkstra&#39;s famous quote still stands, &#34;Testing shows the
presence, not the absence of bugs.&#34;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours) { 
    if(hours &amp;gt; 100) 
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;); 
    auto overtime = hours - 40; 
    return hours * 10 + overtime * 15; 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is obviously wrong, but let&amp;rsquo;s suspend that for a moment and think about
properties i.e. invariants we can verify.&lt;/p&gt;

&lt;p&gt;The first property verifies that we do not write a negative paycheck. The
return type of the function is float, which supports negative values even
though the output domain of our specification forbids it. Lets write
a property over the valid input range of hours that we don&amp;rsquo;t generate negative
pay.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestPositivePay : cppqc::Property
{ 
    PropTestPositivePay() : Property(cppqc::choose(0, 100)) {} 
    
    bool check(const int &amp;amp;  hours) const { 
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5}; 
        return uut::payroll(id, hours) &amp;gt;= 0; 
    }

    std::string name() const
    {
        return &amp;quot;Pay should be positive&amp;quot;;
    }

    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }

    bool trivial(const int &amp;amp;  v) const
    {
        return v &amp;lt; 40;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the input range of this function is small (101 values) so we could run an exhaustive test, but for larger input domains the random generators can really shine. &lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jwright@phaseshift-linux:~/art/CppQuickCheck/b$ ./examples/testPayroll
* Checking property &amp;quot;Pay should be positive&amp;quot; ...
* *** Failed! Falsifiable after 32 tests for input:
*   0: 24
*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cool it found that an input of 0 will falsify the test. Lets add some more tests.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s add a property that verifies for the input range of overtime that the
function doesn’t pay all hours at the $10 rate nor all the hours at the $15
rate. The correct implementation is some mixture of these two.&amp;nbsp; This
brings me to a subtle point when I first heard of property-testing when
studying Haskell. In my naiveté I thought to myself, &amp;ldquo;If I have a model that
verifies the unit under test, aren&amp;rsquo;t I duplicating the implementation?&amp;rdquo;
Furthermore, if I duplicate the implementation, how can I be sure I&amp;rsquo;m not
making the same bugs twice. One response I found online, “we test our C code
in Erlang. It&amp;rsquo;s unlikely to make the same mistake in two separate languages.”
I was wrong however, you don&amp;rsquo;t have to duplicate the functionality. You can
steer the generator to generate data within a range over which a simple
property will be true. Multiple properties together then test the fuller input
domain without requiring 1 single verifier to duplicate behavior. This
property doesn’t exactly know what the correct payroll is. It isn’t
calculating the correct value, it’s just excluding values that it cannot be.
&lt;/p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestOvertimeRateHigher : cppqc::Property 
{ 
    PropTestOvertimeRateHigher()
    :
    Property(cppqc::choose(41, 100)) {} 
    
    bool check(const int &amp;amp;  hours) const { 
    
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5}; 
        auto pay = uut::payroll(id, hours); 
        return pay &amp;gt; hours * 10 &amp;amp;&amp;amp;  pay &amp;lt; hours * 15; //You cannot get paid all overtime or all standard pay
    }

    std::string name() const
    {
        return &amp;quot;You cannot get paid all overtime, or all std time&amp;quot;;
    }

    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }

    bool trivial(const int &amp;amp;  v) const
    {
        return v == 40;
    }

};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Following this thought of excluding a range and testing a simpler property,
lets test the payroll without considering overtime. In this case the
calculation is simple so we can provide a full implementation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;struct PropTestIgnoreOvertime : cppqc::Property
{
    PropTestIgnoreOvertime() : Property(cppqc::choose(0, 40)) {}
    bool check(const int &amp;amp;  hours) const
    {
        std::array&amp;lt;size_t, 5&amp;gt; id{1,2,3,4,5};
        auto pay = uut::payroll(id, hours);
        return pay == hours * 10;
    }

    std::string name() const
    {
        return &amp;quot;Not working overtime makes the math easy.&amp;quot;;
    }
    std::string classify(const int &amp;amp; v) const
    {
        std::ostringstream sstr;
        sstr &amp;lt;&amp;lt; &amp;quot;Hours &amp;quot; &amp;lt;&amp;lt; v;
        return sstr.str();
    }
    bool trivial(const int &amp;amp;  v) const
    {
        return v == 40;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We run the tests a few times and see the failing test cases. These data are random. Running the test multiple times fails differently, but minimization results in the same or similar values each time to help the programmer debug. So let&amp;rsquo;s fix this code and watch the tests pass to avoid the &lt;a href=&#34;http://www.codestrokes.com/2014/08/what-is-a-unit-test/&#34;&gt;mockery and scandal of code review&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40;
    if(overtime &amp;gt; 0)
        return hours * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
*** Failed! Falsifiable after 1 test and 1 shrink for input:
0: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To be honest, while setting up the tests for this post I fully expected the
tests to start passing and this article would end here. Instead I learned some
real value on using these properties as a debugging and design tool. Let&amp;rsquo;s add
a printf to the code to get a sense what&amp;rsquo;s happening&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
Overtime: 18446744073709551576 &amp;lt;--- Whoa what happened there?
*** Failed! Falsifiable after 1 test and 1 shrink for input:
0: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Overtime seems to be an unsigned value, and passing in 0 causes the value to wrap around. The rule (&lt;a href=&#34;http://scottmeyers.blogspot.com/2013/07/when-decltype-meets-auto.html&#34;&gt;http://scottmeyers.blogspot.com/2013/07/when-decltype-meets-auto.html&lt;/a&gt;) assures that overtime becomes a size_t since hours is size_t. We can force floating conversion by stating that 40 is a floating point number.&lt;/p&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t, 5&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40.0; //&amp;lt;-- Force implicit floating point cast
    if(overtime &amp;gt; 0)
        return hours * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Pay should be positive&amp;quot; ...
+++ OK, passed 100 tests (40% trivial).
* Checking property &amp;quot;You cannot get paid all overtime, or all std time&amp;quot; ...
*** Failed! Falsifiable after 1 test and 1 shrink for input:
  0: 60
* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
+++ OK, passed 100 tests.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Argh! Still wrong? The property must be wrong. Notice that the properties are quite simple. No single test verifies the full range, but the properties provide useful documentation and make it easy to reason about the code. The properties are probably correct then. &amp;hellip;yeah, it wasn&amp;rsquo;t the property…&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;float payroll(std::array&amp;lt;size_t  5 ,&amp;gt; person_id, size_t hours)
{
    if(hours &amp;gt; 100)
        throw std::out_of_range(&amp;quot;Hours cannot be greater than 100&amp;quot;);
    auto overtime = hours - 40.0;
    if(overtime &amp;gt; 0)
        return (hours - overtime) * 10 + overtime * 15;
    else
        return hours * 10;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;* Checking property &amp;quot;Pay should be positive&amp;quot; ...
+++ OK, passed 100 tests (40% trivial).
* Checking property &amp;quot;You cannot get paid all overtime, or all std time&amp;quot; ...
+++ OK, passed 100 tests.
* Checking property &amp;quot;Not working overtime makes the math easy.&amp;quot; ...
+++ OK, passed 100 tests.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I started this article wanting to post a simple tutorial on Property testing,
instead I learned to be a bit more careful using auto, and even when the
function is simple, programmers can make mistakes. For the final logic error,
the failing input was 60. Thinking about my directed test method, I would
divide the input into equivalence domains and test the boundary values. For
this input, I would divide standard time to the beginning of overtime. For
directed tests I would have written tests for: 0, 39, 40 41, 99, 100, and 101.
I would have missed the 60 hours bug, and there is the possibility that
I missed typed the numbers on my calculator and type in a wrong expected
value. This example is quite simple but still an interesting demonstration of
property testing. I&amp;rsquo;m looking forward to applying property testing to my next
project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Massively Intelligent Non-Deterministic Luminating Effortless Super Solver</title>
      <link>http://codestrokes.com/2014/02/cracking-subciphercpp/</link>
      <pubDate>Wed, 12 Feb 2014 08:50:00 -0700</pubDate>
      
      <guid>http://codestrokes.com/2014/02/cracking-subciphercpp/</guid>
      <description>&lt;p&gt;I worked the title of this article several times before I finally settled on the subtly epic heading you see above. Hopefully this title will funnel people off google into my blog (delicious SEO). I wanted to push the A.I. component of my solution because A.I. is awesome and mysterious, and cool (and can like solve jeopardy). I was quickly disillusioned however. Really, A.I. isn&amp;rsquo;t magic, rather it&amp;rsquo;s just the same thing computers have been doing for a long time: computing. Sadly this realization took several months in an A.I. class before I was sufficiently crestfallen. A.I. patterns including the hill climbing algorithm used here are indeed &amp;ldquo;intelligent&amp;rdquo; but really it a reflecting of the algorithm designer, not the entity executing the algorithm. So I built a substitution cipher solver in C++. It&amp;rsquo;s fast it uses random numbers i.e. non-deterministic, it uses an A.I. algorithm i.e. Intelligent, it uses threads i.e. Massively, it deciphers i.e. luminates the text and it solves super stuff therefore the title is completely justified. I give you my Massively Intelligent Non-Deterministic Luminating Effortless Super Solver (MINDLESS). If none of that interests you then please stick around and follow the side quest of looking for &lt;a href=&#34;http://justenoughcraig.blogspot.com/2014/01/just-say-no-to-passive-aggressive.html&#34;&gt;emotionally charged parenthesis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cracking substitution ciphers were a fun puzzle I pursued as a child. Substitution ciphers are monoalphabetic ciphers. Meaning a single letter maps to a single letter and that mapping is static. This is opposed to polyalphabetic ciphers where the mapping of letters changes throughout the message. Vigenère Cipher is an example. Given a substitution cipher what are tools are available to the &amp;ldquo;cryptanalyst&amp;rdquo; (the person to breaks ciphers). Firstly, frequency analysis. Frequency analysis supposes the the distribution of letters within the message is essentially the same as the distribution of letters in the English language (&lt;a href=&#34;http://en.wikipedia.org/wiki/Frequency_analysis&#34;&gt;http://en.wikipedia.org/wiki/Frequency_analysis&lt;/a&gt;). However if the message is short, or if the message is intentionally written to skew the letter distribution this technique is difficult. This post looks at a different approach, an artificial intelligence technique called hill climbing.&lt;/p&gt;

&lt;p&gt;Hill Climbing is simply a search technique that uses a &amp;ldquo;fitness&amp;rdquo; measurement (fancy word for number or quality) to determine if the current search path is a useful one.&lt;/p&gt;

&lt;p&gt;First step in building the substitution solver is to assemble some functions that will perform the substitution. I love the string functions in Python to I ported str.translate() to a form useful for my needs
&lt;pre lang=&#34;cpp&#34; escaped=&#34;true&#34;&gt;std::string translate( cost std::string &amp;amp; str, const std::string &amp;amp; table)
{
    std::string s(str);
    std::string::size_type len = str.size();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if ( table.size() != 256 )
{
    throw std::runtime_error(&amp;quot;Improper table size. Size must be 256 chars&amp;quot;);
}

for ( std::string::size_type i = 0; i &amp;amp;lt; len; ++i )
{
    s[i] = table[ s[i] ];
}
return s;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/p&gt;

&lt;p&gt;std::string maketrans(std::string key)
{
    char t1data[256];
    std::iota(std::begin(t1data), std::end(t1data), 0);
    size_t i = &amp;lsquo;A&amp;rsquo;;
    size_t d = &amp;lsquo;a&amp;rsquo; - &amp;lsquo;A&amp;rsquo;;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for(auto k = std::begin(key); k != std::end(key); ++i, ++k)
{
    t1data[i] = *k;
    t1data[i+d] = std::tolower(*k);
}
return std::string(t1data, 256);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}&lt;/pre&gt;
This leverages the fact that in C/C++, characters are simply numbers in ascii. Given a key, we can translate any text:
&lt;pre lang=&#34;cpp&#34; escaped=&#34;true&#34;&gt;std::string substitute(std::string text, std::string key)
{
    auto t1 = pystring::maketrans(key);
    return pystring::translate(text, t1);
}&lt;/pre&gt;
Now we need a fitness measurement. Ngrams are a useful tool here. Ngrams are partial words, and since we are more likely to find partial words in our search than full words, we need to give the program a mechanism for measuring this. This &lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2014/02/quadgrams.7z&#34;&gt;ngram&lt;/a&gt; database is a list of quadgrams and their relative frequency in the English language.&lt;/p&gt;

&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;#include &lt;map&gt;
#include &lt;istream&gt;
#include &lt;string&gt;
#include &lt;ctgmath&gt;
#include &lt;iostream&gt;
struct ngram_score 
{
    struct ngram_datum {
        int freq;
        double weight;
    };
    std::map&lt;std::string, ngram_datum&gt; ngrams;
    double floor;
    size_t l;
    size_t n{0};
    ngram_score(std::istream&amp; in)
    {
        std::string line;
        while(in)
        {
            std::string ngram;
            int freq;
            in &gt;&gt; ngram;
            in &gt;&gt; freq;
            ngrams[ngram].freq = freq;
            n += freq;
        }

        for(auto&amp; i : ngrams)
        {
            i.second.weight = std::log10((double)(i.second.freq)/n);
        }
        floor = std::log10(0.01/n);
        l = 4; //for quadgrams.
    }

    double score(std::string text)
    {
        double score{0};
        auto c = std::begin(text);
        auto e = std::end(text);
        for(; c+l-1 != e; ++c)
        {
            //Get a string of correct length
            std::string ngram(c, c+l);
            auto it=ngrams.find(ngram);
            if(it != ngrams.end())
                score += it-&gt;second.weight;
            else
                score += floor;
        }
        return score;
    }
};&lt;/pre&gt;

&lt;p&gt;We can use this as a scorer for a length of text.
&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;std::ifstream fin(&amp;ldquo;../quadgrams.txt&amp;rdquo;);
ngram_score fitness(fin);
auto score = fitness.score(plaintext);&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;We now have a substitution tool to make substitutions, and we have a numerical way of measuring the resultant quality. Next is to implement the search, this is the mystical artificial intelligence in the program.
&lt;pre lang=&#34;cpp&#34; escaped=&#34;false&#34;&gt;
struct cipher {
    std::string key;
    double score;
    std::string plaintext;
    friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; os, cipher const &amp;amp; c);
};&lt;/p&gt;

&lt;p&gt;cipher break_substitution(std::string cipher_text, std::string skey)
{
    std::transform(std::begin(cipher_text), std::end(cipher_text), std::begin(cipher_text), ::toupper);
    std::uniform_int_distribution&lt;int&gt; distribution(0,25);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cipher p;
p.key = skey;
p.plaintext = substitute(cipher_text, p.key);
p.score = fitness.score(p.plaintext); 
for(size_t i = 0; i &amp;lt; 1000; ++i) //Look at that intelligent for loop
{
    cipher c(p);
    auto a = distribution(g);
    auto b = distribution(g);
    std::iter_swap(std::begin(c.key)+a, std::begin(c.key)+b); //randomly tweak our key
    c.plaintext = substitute(cipher_text, c.key);
    c.score = fitness.score(c.plaintext);  //Measure the quality of the new key.
    if(c.score &amp;gt; p.score)
    {
        p = c; //update the parent
        i = 0; //We&#39;ve made an improvement
    }
}
return p;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;So artificial intelligence, it&amp;rsquo;s just computation.  The trick is that we are a little more intelligent that brute force.  Our algorithm is to generate a random key, substitute the cipher text with that key and measure the quality of the result, i.e., how many partial words are in the result.  Now swap 2 characters, and measure it again. If the result is better continue swapping with that key, if the result is worse throw away that key (branch of the search tree), and return to the previous key (p in this example).&lt;/p&gt;

&lt;p&gt;In this post we looked at how MINDLESS can break substitution ciphers using hill climbing.  If you were following the side-quest, I hope you enjoyed yourself (or rather are overwhelming cross (because of the parenthesis), but be thankful they are balanced).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sean Parent: No Raw Loops</title>
      <link>http://codestrokes.com/2013/11/sean-parent-no-raw-loops/</link>
      <pubDate>Sun, 24 Nov 2013 22:14:50 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/11/sean-parent-no-raw-loops/</guid>
      <description>&lt;p&gt;A group of colleagues and I watched Sean Parent&amp;rsquo;s Going Native Talk on &amp;ldquo;&lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning&#34;&gt;C++ Seasoning&lt;/a&gt;&amp;rdquo;. Parent takes some extreme views on how to use C++, but his examples for using the STL to simplify code are phenomenal. For a recent AI project I decided to apply Parent&amp;rsquo;s &lt;em&gt;goal&lt;/em&gt; of &amp;ldquo;no raw loops&amp;rdquo;, I was blown away by the transformation&amp;hellip; err std::transformation this had on my code. In this post I indented to demonstrate several complex code blocks, or overly specific code blocks what were replaced by some STL magic. Alexander Stepanov says, &amp;ldquo;&lt;a href=&#34;http://www.youtube.com/watch?v=COuHLky7E2Q&#34;&gt;&amp;hellip;code is a liability.&lt;/a&gt;&amp;rdquo; The more code a program has the more likely it contains bugs. The fewer lines of code, the lesser the opportunity for a bug. I haven&amp;rsquo;t quiet decided if I agree with this point, but it does induce thought either way. Sean Parent&amp;rsquo;s methodology seems to agree, for the purposes of this post we&amp;rsquo;ll agree as well.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;So the assignment statement:&lt;/p&gt;

&lt;blockquote&gt;Suppose that you have purchased a bag of candy which has two flavor: cherry (c) and lime (l). We do not know exactly what kind of bag we bought, but we know that it is one of the following types:

&gt; 
&gt; 
    
&gt;   1. 100% cherry (10% likely)
&gt; 
    
&gt;   2. 75% cherry (20% likely)
&gt; 
    
&gt;   3. 50% cherry (40% likely)
&gt; 
    
&gt;   4. 25% cherry (20% likely)
&gt; 
    
&gt;   5. 0% cherry (10% likely)
&gt; 

You take 11 pieces of candy, all happen to be lime. What bag do you most likely have, and what is the probability the next candy will be a lime?&lt;/blockquote&gt;

&lt;p&gt;So lets start with encoding our data.  First we have 2 types of candy: cherry and lime.  Lets represent that:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class lime_type{};
class cherry_type{};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We might expand this later, but for now we just need a way to overload functions on lime candies or cherry candies. This will work just fine.&lt;/p&gt;

&lt;p&gt;Next we have some bags, and associated probabilities&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;enum Bag {
Bag1 =1,
Bag2,
Bag3,
Bag4,
Bag5};

std::vector&amp;lt;Bag&amp;gt; const bags{Bag1, Bag2, Bag3, Bag4, Bag5};

map&amp;lt;Bag, double&amp;gt; apriori{
{Bag1, 0.1},
{Bag2, 0.2},
{Bag3, 0.4},
{Bag4, 0.2},
{Bag5, 0.1}
};

map&amp;lt;Bag, std::pair&amp;lt;double, double&amp;gt;&amp;gt; candy_dist{
{Bag1, {1.00, 0.00}},
{Bag2, {0.75, 0.25}},
{Bag3, {0.50, 0.50}},
{Bag4, {0.25, 0.75}},
{Bag5, {0.00, 1.00}}
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, pretty straight forward, but the magic is about to happen&amp;hellip;&lt;/p&gt;

&lt;p&gt;Next we have to consume data from a file. Each data set is represented by a series of l or c on a single line. We need to print a graph for each line.  Our example data file looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jwright@jwright-LinuxAwesome:~/workspaces/school/cse471/hw15$ cat data1.txt
l l
l l l l l l l l l l l l
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So for our first STL use case. (Actually Boost here, since gcc 4.7.1 doesn&amp;rsquo;t support regex yet, but this functionality will work in gcc 4.9.1).&lt;/p&gt;

&lt;p&gt;The before:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;std::ifstream fin(filename);
    string line;
    while(fin &amp;gt;&amp;gt; line)
    {
        if(line == &amp;quot;l&amp;quot;)
            cout &amp;lt;&amp;lt; &amp;quot;Lime&amp;quot; &amp;lt;&amp;lt; endl;
        if(line == &amp;quot;c&amp;quot;)
            cout &amp;lt;&amp;lt; &amp;quot;cherry&amp;quot; &amp;lt;&amp;lt; endl;
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What&amp;rsquo;s wrong with this code block? Consider if our ls and cs aren&amp;rsquo;t white space delimited. Sensor data is noisy/messy all the time. It would be prudent to deal with this case. This code doesn&amp;rsquo;t block on newlines, and streams all the newlines together. We could wrap this code block with a std::getline() loop, but that&amp;rsquo;s going the wrong direction. No raw loops&amp;hellip; What does the STL provide to deal with this? Essentially we want to tokenize each line with _c_s or _l_s as tokens.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;boost::regex reg(&amp;quot;c|l&amp;quot;); //Construct the regular expression here, since it&#39;s expensive
while(std::getline(fin,line))
{ 
    boost::sregex_token_iterator pos(begin(line), end(line), reg);
    boost::sregex_token_iterator end;
    std::for_each(pos, end, [](boost::sregex_token_iterator tok)
    {
        process(tok-&amp;gt;str());
    });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code isn&amp;rsquo;t directly shorter, but it is certainly more robust. We can deal with extra noise in our data file, and the regex will skip over it gracefully calling our process function once for each l and c it finds on each line.&lt;/p&gt;

&lt;p&gt;Now that we&amp;rsquo;re warmed up, lets check out some better examples. Conditional probabilities have lots of summations, and product chains in them. My initial hack unrolled all these summations. This is both verbose, which can hide errors, but if we can reduce the number of lines we will increase our reliability. First up.&lt;/p&gt;

&lt;p&gt;$$ P( Candy = Lime | Data) = \Sigma_{Bags}(P(lime, Bag_i | Data) $$&lt;/p&gt;

&lt;p&gt;My first hack, looks like something that congealed in a gutter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(cherry_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag3)*p(Bag4, data_type()) +
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This version is has the sad property that a C programmer might say, &amp;ldquo;Awesome, he unrolled the loops. That code will be fast.&amp;rdquo; Stephan T. Lavavej says , &amp;ldquo;&lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler&#34;&gt;Don&amp;rsquo;t help the compiler&lt;/a&gt;&amp;rdquo;. I agree. -funroll-loops will unroll the loops much better than I can.In fact this code as a bug in it. See it?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(cherry_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag3)*p(Bag4, data_type()) + //Boom, check out that hot copy-paste error.
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Corrected, but still not &amp;ldquo;correct&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(lime_type, data_type)
{
//
// \sigma_bags(p(lime, Bag_i | data))
//
double a =
p(lime_type(), Bag1)*p(Bag1, data_type()) +
p(lime_type(), Bag2)*p(Bag2, data_type()) +
p(lime_type(), Bag3)*p(Bag3, data_type()) +
p(lime_type(), Bag4)*p(Bag4, data_type()) + //Boom, check out that hot copy-paste error.
p(lime_type(), Bag5)*p(Bag5, data_type());

return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Beside being verbose, and prone to error. It isn&amp;rsquo;t generate. If we grow our dataset, the loop is not wrong. Can we be sure that we&amp;rsquo;ll find every unrolled loop, and fix it? We can do better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;double p(lime_type, data_type)
{
    //
    // \sigma_bags(p(lime, Bag_i | data))
    //   
    std::vector&amp;lt;double&amp;gt; partials(bags.size());
    std::transform(begin(bags), end(bags), begin(partials), [](Bag b){ return p(lime_type(), b)*p(b, data_type()); });
    double a = std::accumulate(begin(partials), end(partials), 0.0 ); //Gotcha 0.0 instead of 0. 0 will cast the result to an int
    return a;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This version is shorter. The compiler is free to optimize the STL algorithms as needed even unrolling the loops if the compiler deems it will improve the code. This code is readable, but futhermore we can explain this code to a mathematician. Stroustroup says, &amp;ldquo;Express abstracts as the expert in the field does.&amp;rdquo; This function does exactly that. The first step is to compute partial products of $$ P( Lime, Bag_i) * P(Bag_i | Data) $$. Then add the products together. We are agnostic to the number of bags.&lt;/p&gt;

&lt;p&gt;Next what about debugging. I&amp;rsquo;m searching for a bug, and sometimes print statements are the best way to work it out. Lets print out a vector.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector prob;
//...
cout &amp;lt;&amp;lt; &amp;quot;{&amp;quot;;
for(auto&amp;amp; p : prob)
    cout &amp;lt;&amp;lt; p &amp;lt;&amp;lt; &amp;quot;, &amp;quot;;
cout &amp;lt;&amp;lt; &amp;quot;}&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This cannot be bad right? We used the new, shiny range-based for. What can one complain about.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vector prob;
//...
cout &amp;lt;&amp;lt; &amp;quot;{&amp;quot;;
std::copy(std::begin(prob), std::end(prob), std::ostream_iterator&amp;lt;double&amp;gt;(cout, &amp;quot;, &amp;quot;));
cout &amp;lt;&amp;lt; &amp;quot;}&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However we can do &lt;a href=&#34;https://github.com/louisdx/cxx-prettyprint&#34;&gt;even better&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include 
cout &amp;lt;&amp;lt; prob;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even though this program was small, the opportunity to improve quality, and robustness, is ever present. C++ is a growing language, and it&amp;rsquo;s new capabilities are really improving the corner cases in software. One key tool in doing so is learning the STL.  I encourage you to study the STL.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Idiomatic Learning</title>
      <link>http://codestrokes.com/2013/10/idiomatic-learning/</link>
      <pubDate>Sun, 20 Oct 2013 23:00:00 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/10/idiomatic-learning/</guid>
      <description>&lt;p&gt;When learning a new language I find it helpful to study a languages idioms. Idioms exist in a language for a specific reason. Sometimes that reason is to further the principles of the language, other times it’s to mask, or otherwise deal with some underlying design decision of the language. Currently, I am studying Haskell, and currently I am struggle to clarify the idioms of the language. The syntax is still very new and awkward, currently with a total authoring in Haskell of 713 lines.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Python has some interesting idioms, but the one that really helped me when learning was “..tuples should have trailing commas…” At that time, the only other language I knew was C, and PIC Assembly. I was very much a hardware engineer, and Python, for me, was a step out of that hardware-centric mindset. So with such a staunch, inflexible background as this, such an idiom felt, dirty and wrong? My first reaction to this was, “What? Really? Why, are python programmers too lazy?” At first I refused to do this, claiming that my source code was more elegant, and clean. However some time later I learned the second part of this idiom, “…tuples should have trailing commas, BECAUSE syntactically the comma creates the tuple, not the parenthesizes.” Whoa! What an epiphany. From this simple clause, I can now create a tuple with 1 element! The because clause of an idiom, really opens doors in your mind. It really clarifies some subtle point, or characteristic of the language.&lt;/p&gt;

&lt;p&gt;C++ on the other hand has a number of idioms that have become quite ingrained that it&amp;rsquo;s hard to separate, &amp;ldquo;yeah that&amp;rsquo;s just C++ syntax&amp;rdquo;, from, &amp;ldquo;That&amp;rsquo;s just how I do it,&amp;rdquo; to, &amp;ldquo;Oh yeah, I guess template &lt;typename T&gt; class &amp;hellip; isn&amp;rsquo;t very intuitive is it.&amp;rdquo; C++ is a complex multi-paradigm language with one sweeping design decision: You pay for what you use. For instance, take class methods. In C++ class methods are not polymorphic by default. I remember as a fledgling C++ programmer asking my computer science friend, Brian, &amp;ldquo;&amp;hellip;classes are useless without polymorphism. That&amp;rsquo;s just stupid.&amp;rdquo; He tried to explain it to me, but I was probably to frustrated to understand. What I didn&amp;rsquo;t know was the because, and I continued my ignorant use of virtual until I read &lt;a href=&#34;http://www.amazon.com/gp/product/0201543303/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=9325&amp;amp;creativeASIN=0201543303&amp;amp;linkCode=as2&amp;amp;tag=codestro-20&#34;&gt;The Design and Evolution of C++&lt;/a&gt;&lt;img src=&#34;http://ir-na.amazon-adsystem.com/e/ir?t=codestro-20&amp;amp;l=as2&amp;amp;o=1&amp;amp;a=0201543303&#34; alt=&#34;&#34; /&gt;
 that I learned the reason. Polymorphism requires a level of indirection to implement. Doing so affects performance. C++ doesn&amp;rsquo;t push this on you unless you want it, just non-polymorphic by default, virtual if you want. Beautiful. Now as an embedded system designer I love this aspect of C++. I am free to use the features I need without paying for the ones I don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;So now as I approach Haskell, I read blogs, and statements with a temporary suspension of judgement until I learn the because.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Is Monolithic Code Faster?</title>
      <link>http://codestrokes.com/2013/07/is-monolithic-code-faster/</link>
      <pubDate>Sun, 14 Jul 2013 23:00:11 +0000</pubDate>
      
      <guid>http://codestrokes.com/2013/07/is-monolithic-code-faster/</guid>
      <description>

&lt;p&gt;As a software engineer I have a vested interest in disproving this statement. Bjarne Stroustroup says C++ is designed to create efficient abstractions. A software engineer’s  job is to create simple &lt;a href=&#34;http://www.codestrokes.com/2012/09/abstraction-in-plain-english/&#34;&gt;abstractions &lt;/a&gt;to complex systems. State machines form a large part of many systems. The other day, a co-worker came to me, and asked, “Is it better to make straight line code for each case statement, even if it repeats, or is it better to abstraction into functions and make the code ‘cleaner’.”  Is “cleaner” code faster?
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;&lt;/p&gt;

&lt;h2 id=&#34;the-experiment:ad7f9b3b0ebd08ad653cabf663c403bf&#34;&gt;The Experiment&lt;/h2&gt;

&lt;p&gt;The experiment I propose is to make a peanut butter and jelly sandwich, using a finite state machine.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_1089&amp;rdquo; align=&amp;ldquo;alignleft&amp;rdquo; width=&amp;ldquo;97&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2013/07/sm1.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2013/07/sm1-97x300.png&#34; alt=&#34;sm&#34; /&gt;
&lt;/a&gt; State Machine expressed in 4 separate methods.[/caption]&lt;/p&gt;

&lt;p&gt;The state machine has a series of steps, each of which take a number of ticks. The tick simply counts the  amount of time in each state. The ticks simulate work being done in that state. For this experiment we are defining monolithic code to mean a switch() statement with no function calls. For modular code we offer 3 solutions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;a switch statement with the state code abstracted into functions. Each function then returns the state transition.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;States abstracted into C++ objects&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lastly, a high level state machine using Boost MSM.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;code-overview:ad7f9b3b0ebd08ad653cabf663c403bf&#34;&gt;Code Overview&lt;/h3&gt;

&lt;p&gt;For each state machine type, lets look at the an example state to compare their structure. Firstly, the &amp;ldquo;monolithic&amp;rdquo; state:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case EAT_SANDWICH:
if(step_tick &amp;lt;= 0 &amp;amp;&amp;amp; sandwiches_to_eat &amp;lt;= 0) //We&#39;ve eaten all sandwiches
{
    step_tick = 20;
    s = GO_TO_WORK;
}
else if(step_tick &amp;lt;= 0) //We&#39;ve eaten 1 more sandwich
{
    --sandwiches_to_eat;
    step_tick = 10;
    s = REMOVE_BREAD;
}
// else Continue eating current sandwich
break;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here s is the state. At the top of the machine is a switch(s). When the ticks are up, the state transitions to the next state. In this case Go To Work or Remove Bread to make another sandwich.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SandwichState_t eat_sandwich_process()
{
    static int sandwiches_to_eat = 3;
    static int tick = 10;
    --tick;
    if(tick &amp;lt;= 0 &amp;amp;&amp;amp; sandwiches_to_eat &amp;lt;= 0)
    {
        sandwiches_to_eat = 3;
        tick = 10;
        return REMOVE_BREAD;
    }
    else if(tick &amp;lt;= 0)
    {
        --sandwiches_to_eat;
        tick = 10;
        return GO_TO_WORK;
    }
    return EAT_SANDWICH;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This state is the identical to the monolithic, except the state is moved into a function, and the state is returned instead of mutating a variable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int eat_sandwich()
{
    static int sandwiches_to_eat = 3;
    static int tick = 10;
    --tick;
    if(tick &amp;lt;= 0 &amp;amp;&amp;amp; sandwiches_to_eat &amp;lt;= 0)
    {
        sandwiches_to_eat = 3;
        tick = 10;
        s.f = remove_bread;
    }
    else if(tick &amp;lt;= 0)
    {
        --sandwiches_to_eat;
        tick = 10;
        s.f = go_to_work;
    }
    else
        s.f = eat_sandwich;
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This third method is a uses a function pointer s.f. State transitions are performed by mutating the function pointer, and jumping to it e.g. sf();&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Row &amp;lt; EatSandwich       , none  , GoToWork          , ResetTick, user_is_full   &amp;gt;,
Row &amp;lt; EatSandwich       , none  , RemoveBread       , ResetTick, user_is_hungry &amp;gt;,
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is Boost&amp;rsquo;s MSM. essentially, MSM is a domain specific language described completely within a C++ template.&lt;/p&gt;

&lt;h2 id=&#34;results:ad7f9b3b0ebd08ad653cabf663c403bf&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_1097&amp;rdquo; align=&amp;ldquo;alignleft&amp;rdquo; width=&amp;ldquo;300&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2013/07/O2Speedups.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2013/07/O2Speedups-300x225.png&#34; alt=&#34;O2Speedups&#34; /&gt;
&lt;/a&gt; Speedup normalized against the monolithic case. (Compiled with O2 optimization)[/caption]&lt;/p&gt;

&lt;p&gt;I started this project with the full intention of cheating to assure monolithic code is slower than &amp;ldquo;proper&amp;rdquo; code. However, the evidence shows, properly abstracted code can be faster, but there is a limit. As MSM shows one can take abstraction too far or too general such that performance becomes difficult. So How does this happen? One of the most impacting tool for code performance, caching, and compilers have a fancy trick to optimize cache performance. Inlining.&lt;/p&gt;

&lt;h2 id=&#34;inlining:ad7f9b3b0ebd08ad653cabf663c403bf&#34;&gt;Inlining&lt;/h2&gt;

&lt;p&gt;Function inlining is simply a copy-paste operation by the compiler to remove the overhead of a function call. In gcc, and Visual Studio, the compiler is free to inline any function it wills. Conversely, the inline keyword simply provides a suggestion or a hint to the compiler to inline a function. The compiler is free to ignore the suggestion. Once the compiler chooses to inline a function, it simply copies the source from the function and replaces the function call itself.&lt;/p&gt;

&lt;p&gt;However, additional performance is offered beyond simply eliminating the CALL instruction. Optimization is performed in multiple passes. As such removing function calls, can simplify optimization techniques such as global-flow analysis, and register allocation. Therefore, once a function is inlined, additional performance tweaks may be made specific to the environment of the original call. This means the while a function may be optimized on it&amp;rsquo;s own. It will be done so only once. However an inlined function, since the source of the function is laid directly into flow of the program, the compiler can optimize the function specific to that region.&lt;/p&gt;

&lt;p&gt;Many language support function inlining. Java, C++ have an inline keyword. During compilation inlining seems straight forward, however what about dynamic languages? I was surprised to learn that Python inlines.  PyPy uses a Just-In-Time compiler to make inline decisions at runtime. The benefit of inline decisions deferred to runtime, is the JIT is able to see the full program at once, as opposed to only a single file at a time as a batch compiler does.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:ad7f9b3b0ebd08ad653cabf663c403bf&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Cleanly abstracted code can be faster than monolithic code. Even without cheating the benchmark :-).  Compilers make advanced optimizations, as such it&amp;rsquo;s of little benefit to immediately make a blanket statement to try to beat the performance of an optimizing compiler. For dynamic languages, JIT systems make even more comprehensive enhancements offering staggering performance.&lt;/p&gt;

&lt;p&gt;Reference:
&lt;a href=&#34;http://en.wikipedia.org/wiki/Inline_expansion&#34;&gt;http://en.wikipedia.org/wiki/Inline_expansion&lt;/a&gt;
&lt;a href=&#34;http://en.wikipedia.org/wiki/Inline_caching&#34;&gt;http://en.wikipedia.org/wiki/Inline_caching&lt;/a&gt;
&lt;a href=&#34;http://www.iecc.com/linker/linker11.html&#34;&gt;http://www.iecc.com/linker/linker11.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://morepypy.blogspot.com/2011/02/pypy-faster-than-c-on-carefully-crafted.html&#34;&gt;http://morepypy.blogspot.com/2011/02/pypy-faster-than-c-on-carefully-crafted.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Know Its Name</title>
      <link>http://codestrokes.com/2012/07/know-its-name/</link>
      <pubDate>Sat, 21 Jul 2012 19:24:19 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/07/know-its-name/</guid>
      <description>&lt;p&gt;Programming is at it&amp;rsquo;s heart an struggle in communication. Source code is the communication medium with the processor; Comment the medium to other coders, and UML the medium to higher-level communication. Computer Scientists have the stereotype of being poor communicators, but in our own mediums, we&amp;rsquo;re phenomenal. This fact is no where more apparent, than trying to explain source code to someone else. How does one read source code? I&amp;rsquo;m currently, learning Haskell, and my first goal is to understand this question. How can I read (out loud):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[ x * x | x &amp;lt;- nums, x &amp;lt; 7]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;a href=&#34;http://www.haskell.org/haskellwiki/Haskell_Tutorial_for_C_Programmers&#34;&gt;Reference&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;After some searching I found a primer to &lt;a href=&#34;http://stackoverflow.com/questions/7746894/are-there-pronounceable-names-for-common-haskell-operators&#34;&gt;Haskell Vocabulary&lt;/a&gt;. Even at this basic level I see the connection to Mathematics. Therefore I&amp;rsquo;d read this statement as:&lt;/p&gt;

&lt;p&gt;&amp;ldquo;X&amp;rdquo; times &amp;ldquo;X&amp;rdquo;,  Given That, &amp;ldquo;X&amp;rdquo; takes nums, where x is greater-than 7&lt;/p&gt;

&lt;p&gt;One of my favorite quotes about C++ goes like: &amp;ldquo;Except for the syntax, C++ is awesome.&amp;rdquo;.  And in C++ it&amp;rsquo;s even more critical to be able to read source code to someone. Therefore, I post a project to you, study some code you&amp;rsquo;ve written. Then try to read this code to someone else. It will be an interesting, and useful exercise for both of you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building an Interpreter</title>
      <link>http://codestrokes.com/2012/05/building-an-interpreter/</link>
      <pubDate>Mon, 28 May 2012 17:03:55 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/05/building-an-interpreter/</guid>
      <description>

&lt;p&gt;When I started programming, I thought that compilers where these magic behemoths; Oracles which consumed your source code, and prophesied  the resulting program.  I thought that the compiler was an integral part of the &amp;ldquo;system&amp;rdquo;. I was excited to realize that the compiler is simply another program. A program you can write yourself. You can write a compiler, for your very own language.  Go ahead, make up a language, I&amp;rsquo;ll wait&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2012/05/hourglass.gif&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2012/05/hourglass.gif&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Seriously though, making your own language is a very difficult task, and implementing a language useful enough for non-trivial problems is even more difficult. There is however, a very approachable goal here: Domain Specific Languages (DSLs).  DSLs are focused languages useful to a limited group of people for a limited purpose.&lt;/p&gt;

&lt;p&gt;I like to think of DSLs as tools. For example, sometimes one needs to automate a task, its might be easier to write a small program that helps with that task. But it might be even more useful to write a language that allows you to describe the problem better, then one can write a program using the new language to finish the task in an efficient and repeatable way.  The program has limited usefulness beyond its initial application, but for the application at hand, its perfect. SQL is the canonical example. In this post we&amp;rsquo;ll start with a basic grammar in EBNF. We&amp;rsquo;ll translate that to a flex lexer, and connect that to a bison parser. We&amp;rsquo;ll end up with a syntax tree which we&amp;rsquo;ll execute to calculate a result.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;The first step in writing a language is creating the grammar. This is horrifically difficult, however for this example we&amp;rsquo;ll assume we already have a grammar.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Program → Block
Block → {Declaration} {Statement}
Declaration → VariableDeclaration | ConstantDeclaration
VariableDeclaration → var Id {‘,’ Id}
ConstantDeclaration → const Id ‘=’ Number
Statement → Assignment | PrintStmt | IfStmt | DoStmt
Assignment → Id ‘:=’ Expression
PrintStmt → print Expression
IfStmt → if {do Expression ‘-&amp;gt;’ Block end} end
DoStmt → loop {do Expression ‘-&amp;gt;’ Block end} end
Expression → Simple [ Relop Simple ]
Simple → UniTerm {Ampop UniTerm}
UniTerm → Perop UniTerm | Term
Term → Factor [Atop Term]
Factor → ‘(’ Expression ‘)’ | Number | Id
Relop → ‘=’ | ’&amp;lt;’ | ’&amp;gt;’ | ‘/=’ | ‘&amp;lt;=’ | ‘&amp;gt;=’
Ampop → ‘&amp;amp;’
Perop → ‘%’
Atop → ‘@’
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have a grammar, and we can think up some simple test cases. These will be used to evaluate the compiler we&amp;rsquo;re building. This is infinitely important. Compilers are built on the principles of Context-Free-Languages, which by definition are infinite, ergo testing is critically important. Since you cannot possible think of every test case, directed test maybe insufficient, but this discussion is beyond the scope of the post.&lt;/p&gt;

&lt;p&gt;To use Bison to parse this, we need make sure that the grammar is LL(k). Bison is not capable of parsing the entire CFL space, furthermore, &lt;a href=&#34;http://dinosaur.compilertools.net/bison/bison_6.html#SEC42&#34;&gt;bison prefers left-recursion&lt;/a&gt;. Many compiler books encourage right-recursion since&lt;a href=&#34;http://stackoverflow.com/questions/847439/why-cant-a-recursive-descent-parser-handle-left-recursion&#34;&gt; recursive-decent prefers it&lt;/a&gt;. LL(k) is a different animal.  To prove that this grammar is LL(k) compatible, is beyond the scope of this post, but it entails calculating the _First_ and _Follow _sets for each grammar rule.&lt;/p&gt;

&lt;h2 id=&#34;converting-to-bnf:f9baca8760dad209256732958d7afef1&#34;&gt;Converting to BNF&lt;/h2&gt;

&lt;p&gt;Our grammar is in EBNF right now. I&amp;rsquo;ve found it easier to write the bison grammar from the BNF form. I found &lt;a href=&#34;http://lampwww.epfl.ch/teaching/archive/compilation-ssc/2000/part4/parsing/node3.html&#34;&gt;a few tricks&lt;/a&gt; to help. Following these tricks blindly will result in a grammar which is a bit bigger than necessary e.g. the grammar will not be minimum. For our simple grammar this is not a big issue. However, for a production compiler, a minimum grammar is very important.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; Program → Block
 Block → ε | Block Declaration | Block Statement
 Declaration → VariableDeclaration | ConstantDeclaration
 VariableDeclaration → &#39;var&#39; TIDENTIFIER | &#39;,&#39; TIDENTIFIER
 ConstantDeclaration → &#39;const&#39; TIDENTIFIER &#39;=&#39; TNUMBER
 Statement → Assignment | PrintStmt | IfStmt | DoStmt
 Assignment → TIDENTIFIER TASSIGN Expression
 PrintStmt → &#39;print&#39; Expression
 IfStmt → &#39;if&#39; Condition &#39;end&#39;
 DoStmt → &#39;loop&#39; Condition &#39;end&#39;
 Condition → ε | Condition do Expression &#39;-&amp;gt;&#39; Block &#39;end&#39;
 Expression → Simple | Simple RELOP Simple | Simple TEQ Simple
 Simple → UniTerm | Simple TAMPOP UniTerm
 UniTerm → TPEROP UniTerm | Term
 Term → Factor | Factor TATOP Term
 Factor → LPAREN Expression RPAREN | TNUMBER | TIDENTIFIER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that a few rules appear missing. Actually during translation we noted which items can be recognized by the lexer. These tokens are captured by flex/lex, and simplify how much work Bison needs to do. As a general rule the sooner you can translate something the better. This allows your deeper layer to be more abstract e.g. replacing strings in favor of tokens.  (Get &lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2012/05/Bison-Flex.7z&#34;&gt;Bison-Flex&lt;/a&gt; Files). Now that we have the lexer, and syntax analyzer, we can work on &lt;strong&gt;semantic&lt;/strong&gt; analysis. This is an important point that took me a while to understand: syntax is orthogonal to semantics. Said another way, &lt;em&gt;how something is said is separate to what is said&lt;/em&gt;.  Bison will parse the syntax and give use the terminal tokens in the correct order, but it is our responsibility to translate that to actual code.&lt;/p&gt;

&lt;h2 id=&#34;syntax-directed-translation:f9baca8760dad209256732958d7afef1&#34;&gt;Syntax-Directed Translation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Syntax-directed_translation&#34;&gt;Syntax-Directed Transalation&lt;/a&gt;, is one method for attaching semantic actions to the rules of a grammar. I image that the grammar rule is  the line to the constructor of a C++ class. For example, take the _Assignment _rule:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Assignment → TIDENTIFIER TASSIGN Expression
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This rule has 2 important parts, TIDENTIFIER and the Expression. The TASSIGN token is implied by the rule itself. This allows us to write a class as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct Assignment {

    Assignment(string id, Expression* rhs):
    _rhs(rhs),
    _identifier(id)
    {
    }

    virtual string ToString()
    {
        return &amp;quot;Assignment:: &amp;quot;;
    }

    virtual void Execute()
    {
        int value = _rhs-&amp;gt;Execute();
        programSymbolTable-&amp;gt;GetSymbol(_identifier)-&amp;gt;SetValue(_rhs-&amp;gt;Execute());
    }

  Expression* _rhs;
  string const _identifier;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Following in this way we can complete semantic actions for each rule. To finish our interpreter we simply need to leverage the Bison PDA to link all the objects together.&lt;/p&gt;

&lt;h2 id=&#34;the-abstract-syntax-tree:f9baca8760dad209256732958d7afef1&#34;&gt;The Abstract Syntax Tree&lt;/h2&gt;

&lt;p&gt;Behind the scenes, Bison uses a very efficient table driven parser. For this project, I&amp;rsquo;ve found its easier to treat Bison parser as a black-box, and independent of how is actually implemented, imagine Bison uses a theoretical Push-down Automata.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;340&amp;rdquo; caption=&amp;ldquo;PDA from Wikipedia.org&amp;rdquo;]&lt;a href=&#34;http://en.wikipedia.org/wiki/Pushdown_automaton&#34;&gt;&lt;img src=&#34;http://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Pushdown-overview.svg/340px-Pushdown-overview.svg.png&#34; alt=&#34;PDA from wikipedia&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;From this picture Bison&amp;rsquo;s &lt;em&gt;$$_ token represents the A. The input tape is preprocessed by flex. Ergo, at this point the input tape, is a&lt;/em&gt; string of tokens_, not a string of characters. We mentioned earlier that Bison prefers left-recursion, this is directly attributed to the PDA architecture it uses. Bison&amp;rsquo;s method of matching the stack allows right-recursion to use bounded stack space. We&amp;rsquo;ve discussed before how &lt;a href=&#34;http://www.codestrokes.com/2011/11/parallel-binary-buddy-the-friendly-memory-manager/&#34;&gt;memory allocation&lt;/a&gt; is one of the slowest operations a program can perform, therefore limiting the memory usage is always a meaningful performance enhancement.&lt;/p&gt;

&lt;p&gt;Bison&amp;rsquo;s will now parse the input tokens for use, and as it matches each rule, automatically recurse through the rules until it reaches a terminal. This in turn will call your semantic actions in the reverse order to compose your tree. By returning each new node of the tree into the $$, Bison will pass the chain of objects back up the parse tree. Let&amp;rsquo;s see an example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;N := i &amp;amp; 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an assignment. the bison follows our rules in the following order:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Assignment : TIDENTIFIER TASSIGN Expression
TIDENTIFIER = &#39;N&#39;, matched by flex
TASSIGN = &#39;:=&#39; matched by flex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Expression is a non-terminal so keep parsing
Our stack at this point has the following items in it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TIDENTIFIER:&#39;N&#39;
TASSIGN:&#39;:=&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now Bison has to resolve the Expression rule into terminals, so bison jumps to the Expression Rule:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Expression : Simple
           | Simple RELOP Simple
           | Simple TEQ Simple
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simple matches, so keep parsing.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Simple: UniTerm
           | Simple TAMPOP UniTerm
TAMPOP = &#39;&amp;amp;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;UniTerm matches so keep parsing. Following in this way, we eventually reach the Factor rule:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Factor : LPAREN Expression RPAREN { $$ = $2; }
        | TNUMBER { $$ = new Factor($1); } &amp;lt;-- Runs this one for the &#39;1&#39;
        | TIDENTIFIER { $$ = new Factor(*$1); } &amp;lt;-- Runs this for the &#39;i&#39;
TNUMBER = &#39;1&#39;
TIDENTIFIER = &#39;i&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we return up the parse tree, at each semantic action we pass the newly created object into the $$ token. The power of Bison, is how it calls the rules in the correct order allowing you to compose your tree correctly, or recognize a syntax error if rules don&amp;rsquo;t match.&lt;/p&gt;

&lt;p&gt;At this point there a fork in the road. We can either execute our tree directly, which makes our interpreter complete, or we can move on to code-generation. Code generation will translate the AST we built into some other language. This target language is frequently C for DSLs. C allows for massive flexibility, while retaining platform portability. Every platform has a C compiler, there by targeting C, your language also runs on every platform. This difference between interpreter and compiler is subtle, since some interpreters include virtual machines, and translate the source code to an intermediate form which the internal virtual machine executes. Python is one such example of this.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:f9baca8760dad209256732958d7afef1&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Bison is a powerful tool, combined with Syntax-Directed translation, we have a powerful tool for matching languages. Bison can parse streaming data as well, by combining these techniques, one can recognize a stream of commands sent over a network, or other dynamic source. For the embedded spaces this offers a very powerful way of interfacing with downstream sensors and ECUs. Bison is also extremely efficient and uses a bounded memory stack, allowing use in the smallest of microcontrollers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Anderson Smart-Pointer Idiom Updated!</title>
      <link>http://codestrokes.com/2012/05/anderson-smart-pointer-idiom-updated/</link>
      <pubDate>Sun, 06 May 2012 07:00:10 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/05/anderson-smart-pointer-idiom-updated/</guid>
      <description>&lt;p&gt;C++11 provides us with a ton of new tools for expressing complex ideas in an efficient way. C++11 is unique among modern languages in that it provides a productive syntax, while also generating exceptionally fast code. For the first time ever, software engineers are responsible for increasing the performance of software systems. For decades we&amp;rsquo;ve been standing on the shoulders of hardware engineers. Hardware engineers have been increasing the clock speeds of our processors, but we&amp;rsquo;ve hit a physical limit. It&amp;rsquo;s our turn to pick up the baton in this relay race and get to the finish line. C++11 provides a number of tools to help us get there, and smart pointers are one such tool.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
The &lt;a href=&#34;http://www.codestrokes.com/2011/10/making-c-like-python-the-anderson-smart-pointer-pattern/&#34;&gt;Anderson Smart-Pointer idiom&lt;/a&gt; is a pattern developed by a &lt;a href=&#34;http://www.chrisanderman.com/&#34;&gt;colleague of mine&lt;/a&gt;. It supplants the constructor of a class with a factory method, to eliminate all raw pointers in a software system. Secondly, it provides typedefs for the smart pointers so one may use a terse type to express a more verbose concept. C++11 provides three tools which allow us to make this pattern more generic, while also increasing its performance.&lt;/p&gt;

&lt;p&gt;C++11 allows us to apply the &lt;a href=&#34;http://en.wikipedia.org/wiki/Don&#39;t_repeat_yourself&#34;&gt;DRY&lt;/a&gt; principle to the factory method.  Variadic templates allow us to render a completely generic version of the factory method. Until C++11, one was forced to duplicate the parameter list of the constructor in the factor method. This violates DRY, making maintenance more difficult. The factory construct now looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;template&amp;lt;typename... Ts&amp;gt;
 static SmartClass::Ptr construct(Ts... vs)
 {
 SmartClass::Ptr c = std::make_shared&amp;lt;SmartClass&amp;gt;(SmartClass(vs...));
 c-&amp;gt;self = c;
 return c;
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Except for the class name, this method never changes. This is powerful since it creates a &lt;a href=&#34;http://en.wikipedia.org/wiki/Separation_of_concerns&#34;&gt;separation of concerns&lt;/a&gt;. The factory method is only concerned with creating a smart-pointer handle to some dynamically created object. Any specific details in the constructor, i.e. the parameters, are forwarded to the actual constructor. This renders thee factory method completely generic.&lt;/p&gt;

&lt;p&gt;Line 4 also debuts another C++11 addition: perfect-forwarding. C++11 contains a special non-member constructor for shared pointers. This special constructor leverages the STL&amp;rsquo;s &lt;a href=&#34;http://en.cppreference.com/w/cpp/utility/forward&#34;&gt;perfect-forwarding&lt;/a&gt; to remove as much function-call overhead as possible. This small fragment of code, leverages the massively powerful &lt;a href=&#34;http://en.wikipedia.org/wiki/C%2B%2B11#Rvalue_references_and_move_constructors&#34;&gt;move-semantics&lt;/a&gt; in C++11, generating extremely efficient code.&lt;/p&gt;

&lt;p&gt;The last component which rounds out our updated idiom is that the smart pointer templates are now part of the standard namespace. Together the entire pattern looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;memory&amp;gt;
#include &amp;lt;iostream&amp;gt;

class SmartClass
{
public:
typedef std::shared_ptr&amp;lt;SmartClass&amp;gt; Ptr;
typedef std::weak_ptr&amp;lt;SmartClass&amp;gt; WeakPtr;
template&amp;lt;typename... Ts&amp;gt;
static SmartClass::Ptr construct(Ts... vs)
{
SmartClass::Ptr c = std::make_shared&amp;lt;SmartClass&amp;gt;(SmartClass(vs...));
c-&amp;gt;self = c;
return c;
}
virtual ~SmartClass();
private:
SmartClass(int param1, char param2);
SmartClass::WeakPtr self;

};

int main(int argc, const char *argv[])
{
SmartClass::Ptr p = SmartClass::construct(2, &#39;c&#39;);
return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice two things about the updated pattern. Even though the construct method is a template, we do not have to explicitly enumerate the constructor&amp;rsquo;s types at the call site (line 25). Secondly, even though we&amp;rsquo;re using a template, the entire class does not have to exist in the header file, only the template part, i.e. the construct method needs to be in the header. This is useful since it allows one to hide business logic in the cpp file, while still leveraging a generic template.&lt;/p&gt;

&lt;p&gt;The updated Anderson smart-pointer idiom, extends an already powerful pattern into a more generic, high performance pattern. By applying &lt;a href=&#34;http://en.wikipedia.org/wiki/Don&#39;t_repeat_yourself&#34;&gt;DRY&lt;/a&gt; to the factory method, we are able to create a completely generic version of the constructor, which improves maintenance and separates the concerns of class construction from the memory management. Secondly, by leveraging the move semantics of &lt;em&gt;make_shared&amp;lt;&amp;gt;()&lt;/em&gt;, we create a shared_ptr with almost zero overhead. Lastly, the most powerful piece of this update is that  the public interface if this pattern has zero change. Code which already uses this patterns doesn&amp;rsquo;t have to change. Updating the factory method and recompiling will pull in all the benefits.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multicast Delegates in C&#43;&#43;11</title>
      <link>http://codestrokes.com/2012/03/multicast-delegates-in-c11/</link>
      <pubDate>Sun, 25 Mar 2012 05:32:43 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/03/multicast-delegates-in-c11/</guid>
      <description>&lt;p&gt;C# has a wonderfully flexible delegate system capable of multicast events.  This simple tool makes event driven software easier to write, and reduces coupling between objects. In 2003 Herb Sutter implemented a general form of the Observer pattern [1].  He called this the multi_function. It uses a mixture of TR1 and boost components to build a multi-cast delegate similar to C#&amp;rsquo;s.  Fast-forward 9 years, and we now have variadic-templates thanks to C++11.  Variadic-Templates allow us to patch a missing component in Sutter&amp;rsquo;s multi_function.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;&lt;/p&gt;

&lt;p&gt;Variadic Templates sound like a overwhelming cacophony. Templates are complex enough already, why do we need to add more complexity to the issue? However, Variadic Templates don&amp;rsquo;t have to be as difficult as they could be.  Variadic Templates have the potential to destroy readability. They are extremely abstract tools. At a recent conference, Andrei Alexandrescu, not wanting to disappoint, defined the variadic-variadic-template-template [3]. Templates can be abused, and the varadic is no exception. However, when used judiciously varadic templates are just a tool that can solve some very real-world issues.&lt;/p&gt;

&lt;p&gt;We are going to use the type expansion effects of variadic templates to consolidate some code. Sutter uses a template to implement to operator() of his multi_function. When one calls this operator, multi_function in-turn calls the operator() of each stored function. Hence, the multi-cast behavior.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void operator()() const {
    for( std::list&amp;lt;tr1::function&amp;lt;F&amp;gt; &amp;gt;::const_iterator i = l_.begin(); i != l_.end(); ++i )
      (*i)();
  }

  template&amp;lt;typename T1&amp;gt;
  void operator()( T1 t1 ) const {
    for( std::list&amp;lt;tr1::function&amp;lt;F&amp;gt; &amp;gt;::const_iterator i = l_.begin(); i != l_.end(); ++i )
      (*i)( t1 );
  }

  template&amp;lt;typename T1, typename T2&amp;gt;
  void operator()( T1 t1, T2 t2 ) const {
    for( std::list&amp;lt;tr1::function&amp;lt;F&amp;gt; &amp;gt;::const_iterator i = l_.begin(); i != l_.end(); ++i )
      (*i)( t1, t2 );
  }

  template&amp;lt;typename T1, typename T2, typename T3&amp;gt;
  void operator()( T1 t1, T2 t2, T3 t3 ) const {
    for( std::list&amp;lt;tr1::function&amp;lt;F&amp;gt; &amp;gt;::const_iterator i = l_.begin(); i != l_.end(); ++i )
      (*i)( t1, t2, t3 );
  }

  // etc.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The _etc _is the point.  This implementation is quite limiting, one has to implement the operator() for every possible number of operands in the target function. Google Mock also has a similar issue [4]. Google fixes it by using a code generator that implements the method up to a large number of parameters. C++11 fixes this.&lt;/p&gt;

&lt;p&gt;Templates are designed to generate code at compile time to leverage source code reuse. Alexandrescu says that templates are source-code reuse, while inheritance is binary reuse. Since source code is more general than binary, templates are more general than inheritance.  Variadic templates allow the compiler to accept a variable number of arguments then at compile time, special syntax is used to expand the expressions.  Here is the above code consolidated into a variadic.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;template&amp;lt;typename... Ts&amp;gt; //Expand all the Types into a comma separated list
void operator()(Ts... vs) const {

    for(auto i = begin(l_); i != end(l_); ++i) //Iterator over the callbacks
    {
        (*i)(vs...); //Expand all the values into a comma separated list
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simpler, right? Sadly, gcc currently has a bug which prevents variadics and lambdas from playing nicely together [2].  The power of this expression is the new &amp;hellip; syntax.  I follow Alexandrescu&amp;rsquo;s cue to pluralize the template arguments, Ts and vs respectively. Ts are Types, and vs are Values.  The compiler will accept any number arguments, and type-safely expand the argument list. This vastly expands to generality of this class, without drastically increasing the complexity. This is certainly simpler than using separate code-generation phase to expand the type lists prior to compilation.&lt;/p&gt;

&lt;p&gt;Variadic Templates are a powerful tool; there is certainly the potential to create some very obsucated code with this tool. However with judicious use, very useful and extensive interfaces are possible.&lt;/p&gt;

&lt;p&gt;Thank you to the stackoverflow community for guidance on this, and a massive thank you to Herb Sutter for implementing the original multi_function.&lt;/p&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://drdobbs.com/cpp/184403873?pgno=3&#34;&gt;http://drdobbs.com/cpp/184403873?pgno=3&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://stackoverflow.com/questions/9856859/variadic-template-lambda-expansion&#34;&gt;http://stackoverflow.com/questions/9856859/variadic-template-lambda-expansion&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://gcc.gnu.org/bugzilla/show_bug.cgi?id=41933&#34;&gt;http://gcc.gnu.org/bugzilla/show_bug.cgi?id=41933&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Variadic-Templates-are-Funadic&#34;&gt;http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Variadic-Templates-are-Funadic&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://code.google.com/p/googlemock&#34;&gt;http://code.google.com/p/googlemock&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Compile-Time Polymorphism</title>
      <link>http://codestrokes.com/2012/02/compile-time-polymorphism/</link>
      <pubDate>Sun, 05 Feb 2012 21:14:29 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/02/compile-time-polymorphism/</guid>
      <description>

&lt;p&gt;Polymorphism is a tool in object orientation, which allows us to model behavior, while simultaneously leverage existing code. Polymorphism allows is behavior reuse.  In C++ polymorphism, comes in 2 flavors, the standard runtime variant, and a curious compile time variant.  Runtime polymorphism, like Java, leverages virtual functions to dynamically bind[1. With virtual functions the compiler doesn&amp;rsquo;t know which method to call until runtime. In C++ this is implemented with the &lt;a href=&#34;http://en.wikipedia.org/wiki/Virtual_method_table&#34;&gt;virtual method table&lt;/a&gt;] a method at the call site. Compile Time polymorphism uses templates, to bind at compile time, thus negating the performance affect of virtual functions.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Polymorphism is a powerful concept. Polymorphism is a powerful tool in object-orientation, allowing one to realistically model the behavior or structure of some entity in software. This is key to any software design. Regardless, of idioms, language, paradigm, a realistic model is essential to a good design. If follow every best practice in software design, but your system doesn&amp;rsquo;t accurately reflect the real-world model, your software will be difficult to work with, and it will be impossible to bring new people on your project.  An accurate portrayal is required.&lt;/p&gt;

&lt;p&gt;C++ affords us 2 forms of g: compile-time [2. Compile-Time polymorphism is also known as static polymorphism. I, however find this nomenclature confusing.  &amp;rdquo;static dynamicism&amp;rdquo;&amp;hellip;. Um, what?], and runtime.  Runtime is the most straightforward, and uses virtual functions.  However, as we&amp;rsquo;ll see later, virtual function have their own performance costs.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2012/02/SuperSimplePolymorphism.png.jpg.jpeg&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2012/02/SuperSimplePolymorphism.png.jpg.jpeg&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re going to implement this very simple hierarchy, to demonstrate polymorphism is its most basic form.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct Base {
    Base (){}
    virtual ~Base (){}
    virtual void DoSomething(){
        cout &amp;lt;&amp;lt; &amp;quot;Hello From Base.&amp;quot; &amp;lt;&amp;lt; endl;
    }
};

struct Child : public Base {
    Child (){}
    virtual ~Child (){}
    virtual void DoSomething() {
        cout &amp;lt;&amp;lt; &amp;quot;Hello from Child.&amp;quot; &amp;lt;&amp;lt; endl;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using the following driver code.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main(int argc, char const *argv[]){   
    Base* b = new Child();
    b-&amp;gt;DoSomething();
    delete b;
}




}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Produces the following output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash $ ./a.out
Hello from Child
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works, and its a familiar idiom. However virtual functions have a some performance issues. Since the call isn&amp;rsquo;t bound until until runtime, the methods cannot be inlined, and will probably incur a cache miss [1. &lt;a href=&#34;http://coldattic.info/shvedsky/pro/blogs/a-foo-walks-into-a-bar/posts/3&#34;&gt;A foo walks into a bar&lt;/a&gt;] , which on modern processors with the very deep caches is a very costly effect.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2012/02/Untitled-1.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2012/02/Untitled-1.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Secondly, even with cacheing aside virtual functions are about 2.5 times slower than direct function calls; where as inlining, i.e. zero-function overhead is about 20 times faster [1. &lt;a href=&#34;http://assemblyrequired.crashworks.org/2009/01/19/how-slow-are-virtual-functions-really/&#34;&gt;How Slow Are Virtual Functions Really&lt;/a&gt;]. So this is a major issue is performance critical code, such as games. The EA directly states that virtual functions forbidden in their code [1. &lt;a href=&#34;http://assemblyrequired.crashworks.org/2008/12/22/ea-stl-prevents-memory-leaks/#more-92&#34;&gt;How the EA prevents Memory Leaks&lt;/a&gt;].  However, polymorphism is a powerful tool. Are we relegated to a &amp;ldquo;lower&amp;rdquo; form of Object-Orientation with writing performance critical code? No. In fact the opposite is true.  C++&amp;rsquo;s template system is powerful and allows us to add dnasicm at compile time.&lt;/p&gt;

&lt;p&gt;We can implement the same behavior as the UML figure above using templates. This improves the performance of our code in two ways. Firstly, by omitting virtual function we pickup a ~2.5x boost. Secondly, by using composition instead of inheritance we also get a small bump, and the compiler is more likely to inline the &amp;ldquo;inner&amp;rdquo; function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;template &amp;lt;typename ChildType&amp;gt;
struct Base {
    Base (){}
    virtual ~Base2 (){}
    void DoSomething() {
        myChild.DoSomething(); // This is the &amp;quot;inner&amp;quot; function.
    }
private:
    ChildType myChild;
};

struct Child /* Notice the lack of inheritance here */{
    Child () {}
    virtual ~Child(){}
    void DoSomething(){
        cout &amp;lt;&amp;lt; &amp;quot;Hello from Child.&amp;quot; &amp;lt;&amp;lt; endl;
    }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our driver is similar to before, except for the instantiation. Instead of inheriting behavior from a base class and overriding it, the Child, or implementing type, is passed in as an instantiation argument. This creates a new type, which is the dynamic behavior we want. Using the following driver code, we achieve the same output as before.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main(int argc, char const *argv[]){   
    Base&amp;lt;Child&amp;gt;* b = new Base&amp;lt;Child2&amp;gt;();
    b-&amp;gt;DoSomething();
    delete b;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;C++11 (-std=c++0x in gcc4.6) allows one 1 more improvement in the driver code to prevent memory leaks.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main(int argc, char const *argv[]){   
auto b2 = make_shared&amp;lt;Base2&amp;lt;Child2&amp;gt; &amp;gt;();
b2-&amp;gt;DoSomething();
//Notice we don&#39;t have to call delete. Woot, exception safety!
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So polymorphism is a powerful tool for creating dynamicism in programs, however with the inherent [1. Pun intended] performance issues the standard form of polymorphism is not the tool for every job. C++ templates allow use a manageable way to achieve similar behavior at compile time!&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;references:e250069d864db99c70bebd39675460a8&#34;&gt;References&lt;/h4&gt;
</description>
    </item>
    
    <item>
      <title>Modern C&#43;&#43;</title>
      <link>http://codestrokes.com/2012/01/modern-c/</link>
      <pubDate>Sun, 22 Jan 2012 18:10:30 +0000</pubDate>
      
      <guid>http://codestrokes.com/2012/01/modern-c/</guid>
      <description>&lt;p&gt;I found an awesome talk on how the new changes of C++11 are modernizing, an already fantastically powerful language. &lt;a href=&#34;http://channel9.msdn.com/Events/BUILD/BUILD2011/TOOL-835T&#34;&gt;http://channel9.msdn.com/Events/BUILD/BUILD2011/TOOL-835T&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this talk, Herb Sutter does two things I feel are quite admirable. Firstly, despite this being a Microsoft conference, he talks only about standard, portable C++ until the final minutes.&lt;/p&gt;

&lt;p&gt;Secondly, he very clearly, compares idioms we currently use, to the new C++11 idioms. This made it very easy for me to see the value of what C++11 provides. If you want to start using C++11 in your own projects checkout this talk!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallel Binary Buddy: The Friendly Memory Manager</title>
      <link>http://codestrokes.com/2011/11/parallel-binary-buddy-the-friendly-memory-manager/</link>
      <pubDate>Wed, 23 Nov 2011 18:50:20 +0000</pubDate>
      
      <guid>http://codestrokes.com/2011/11/parallel-binary-buddy-the-friendly-memory-manager/</guid>
      <description>

&lt;p&gt;Fragmentation, the
allocator&amp;rsquo;s sin. Each byte
A buddy, A friend&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Introduction&lt;/p&gt;

&lt;p&gt;Memory management is pervasive in all forms of software, not just operating systems. Embedded Systems, when dynamic memory is acceptable, tend to use memory pools to the heap. Standard desktop applications use the platform&amp;rsquo;s std::new or malloc. However, when a system is more complex, a memory manager may be used. Memory managers allow the programmer to strictly control application memory, in a way that flows with the rest of the system&amp;rsquo;s design. A perfect example of the power a memory manager can provide, is MegaTexture, a component in id Software&amp;rsquo;s new id Tech 5 graphics engine [&lt;a href=&#34;Report.html#SIGGRAPH2009&#34;&gt;5&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;In a video game, the system has 3 levels of memory: Non-Volatile Storage (e.g. Flash or rotating media), System Memory (RAM), and Video RAM. Video RAM is by far the fastest, yet most scarce, ergo the most precious. id Tech 5 implemented a memory manger that streams graphics data between these 3 memory layers. This allows the programmer to load enormous textures; textures which would not normally fit into Video RAM. The Memory Manager treats the System RAM, and finally Non-Volatile Storage as virtual memory for the Video card. Since MegaTexture is part of a game engine, the MegaTexture knows what parts of the map need to be drawn, depending on the player&amp;rsquo;s locale. Using this spacial locality, the memory manager transfers the correct textures in varying levels of detail into the video card&amp;rsquo;s RAM. This way, the system always has the correct textures ready to go. This fantastic system allows id Software to run incredibly high resolution screens at 60 frames per second!&lt;/p&gt;

&lt;p&gt;id software&amp;rsquo;s MegaTexture is just one example of how a custom memory manager can simplify, and improve the quality of one&amp;rsquo;s software. For this project we implemented a parallel memory manager using the Binary Buddy allocation scheme. This scheme is used in tandem with the slab allocator, to provide dynamic memory for kernel objects in the Linux kernel [&lt;a href=&#34;Report.html#kalloc&#34;&gt;2&lt;/a&gt;, p. 134].&lt;/p&gt;

&lt;h1 id=&#34;architecture:723bd9d9790e5a45b54c88d06f0b5807&#34;&gt;Architecture&lt;/h1&gt;

&lt;p&gt;The parallel architecture is largely influenced by the design offered by Johnson and Davis in their paper [&lt;a href=&#34;Report.html#johnson&#34;&gt;3&lt;/a&gt;]. I used the POSIX threading library to add parallelism to the allocator. As a deviation from the design offered by Johnson, this design uses templates to prevent internal fragmentation. Templates allow one to pass in the C++ type as an argument to the allocator. The allocator, using templates, dynamically creates blocks of precisely that size. This guaranteeing that allocations will be optimized for that specific size, and multiples of that size. In this way, allocating arrays of similar objects will not result in internal fragmentation.&lt;/p&gt;

&lt;p&gt;Interestingly, templates had a bigger affect than just space-efficiency. The templates create compile time generated pointers of the correct block size, regardless of the type. Since transactions are not translated to bytes, the code is more direct, and easier to understand. The templates created a custom block type which simplified manipulating memory blocks instead of raw byte pointers.&lt;/p&gt;

&lt;h1 id=&#34;performance:723bd9d9790e5a45b54c88d06f0b5807&#34;&gt;Performance&lt;/h1&gt;

&lt;p&gt;I measured the performance of the allocator using 2 metrics: overhead and allocations per second. The former is defined as the number of pending allocation requests, i.e. time spent blocked on a synchronization primitive. This time is an artifact of locking the individual memory levels while another thread allocates memory. This is wasted time and directly detrimental to the performance of the allocator. The latter is defined as raw query speed.&lt;/p&gt;

&lt;p&gt;I setup 3 tests using allocators of various sizes. Each allocator requests memory blocks until full see Tests/TestInstrument.cpp for an example of this. As a comparison I ran a similar test against std::new. See Table 1 for results.&lt;/p&gt;

&lt;table &gt;**Table 1:**
Allocation Performance
&lt;tbody &gt;
&lt;tr &gt;

&lt;td &gt;
&lt;table cellpadding=&#34;3&#34; &gt;
&lt;tbody &gt;
&lt;tr &gt;

&lt;td align=&#34;LEFT&#34; &gt;Scheme
&lt;/td&gt;

&lt;td align=&#34;CENTER&#34; &gt;Allocation Speed (ms)
&lt;/td&gt;

&lt;td align=&#34;RIGHT&#34; &gt;GB/Sec
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;

&lt;td align=&#34;LEFT&#34; &gt;std::new
&lt;/td&gt;

&lt;td align=&#34;CENTER&#34; &gt;1.3
&lt;/td&gt;

&lt;td align=&#34;RIGHT&#34; &gt;102.9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;

&lt;td align=&#34;LEFT&#34; &gt;Spinlock
&lt;/td&gt;

&lt;td align=&#34;CENTER&#34; &gt;5.9
&lt;/td&gt;

&lt;td align=&#34;RIGHT&#34; &gt;22.2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;

&lt;td align=&#34;LEFT&#34; &gt;Mutex
&lt;/td&gt;

&lt;td align=&#34;CENTER&#34; &gt;12.4
&lt;/td&gt;

&lt;td align=&#34;RIGHT&#34; &gt;2.6
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_486&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;695&amp;rdquo; caption=&amp;ldquo;Figure 1: Raw Allocation performance.&amp;ldquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/SpeedComparisons.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/SpeedComparisons-1024x768.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;To measure overhead in the allocator, I instrumented the request pending queues to track a ``high-water mark&amp;rdquo;. I tracked this overhead over various sized allocators, and found that the smallest levels never had waiting blocks. I expected this for the smallest levels, yet consistently the smallest 3 levels never requested an allocation to wait (Figure 3). The largest levels have at least 1 pending request, from the initial recursive split. Additionally, regardless of the allocator&amp;rsquo;s native block size, the graph is similar. Block size does not affect the number of pending requests.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_481&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;695&amp;rdquo; caption=&amp;ldquo;Figure 3: Pending requests as a measure of overhead.&amp;ldquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/combined.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/combined-1024x768.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;Beating std::new&lt;/p&gt;

&lt;p&gt;&lt;em&gt;new&lt;/em&gt; is fast. I wanted to out perform &lt;em&gt;std::new&lt;/em&gt;. I was not successful; however more intrigue was the effect pthreads primitives play in the performance of an application. My initial implementation using pthread_mutex_t to synchronize. This resulted in a 10x slow-down over std::new. Simply replacing the mutexes with pthread_spinlock_t resulted in a 2x speedup over mutexes as shown in Figure 2.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_482&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;695&amp;rdquo; caption=&amp;ldquo;Figure 2:On a multicore machine, spinlocks result in better performanceover mutexes&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/NormalizedSpeedComp.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/11/NormalizedSpeedComp-1024x768.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;It is important to not however that this trade-off only happens on a multicore machine. Spinlocks are essentially very tight while loops, waiting on some condition. This does not suspend the thread. On a single core machine, spinlocks are very inefficient. The different here is that the average amount of time spent waiting for the lock, is less than cost of a system() call. So on a multicore we can block one core while another core completes the parallel request and releases the lock.&lt;/p&gt;

&lt;p&gt;Extending the STL&lt;/p&gt;

&lt;p&gt;The Binary Buddy memory allocator is unsuitable as a general purpose STL allocator since it does not maintain the memory interface for all STL containers. For example, the STL vector guarantees that the successive items in the vector will be stored contiguously in memory. In a sense, raw pointers are permitted to access a vector, since the binary buddy does not make this guarantee, it is unsuitable for the vector [&lt;a href=&#34;Report.html#cppstl&#34;&gt;4&lt;/a&gt;, p. 727]. However, the this allocator is sufficient for the STL list, or any container which is only indexed by iterators.&lt;/p&gt;

&lt;p&gt;STL Allocators also allow for an interesting performance boost by offering locality hints to the allocator [&lt;a href=&#34;Report.html#cppstl&#34;&gt;4&lt;/a&gt;, p. 733]. These hints allow upper level software to suggest efficient memory locations to lower level allocation algorithms. These hints offered as memory addresses, can boost performance up to 13% over the default FreeBSD allocator[&lt;a href=&#34;Report.html#locality&#34;&gt;1&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;More interestingly than performance, is the additional capabilities one has when using a custom allocator over a default platform one. By manually managing the heap, the developer has access to all memory use by the system. One could serialize that memory to disk, and provide a fast initialization mechanism for application restarts. A sort-of suspend for one&amp;rsquo;s application. Additionally, since the allocator is setup as a gatekeeper for all application memory, its easier to log and track who is requesting what.
While this would hamper performance it is an interesting debugging tool for difficult to reproduce, multi-threaded memory bugs.&lt;/p&gt;

&lt;p&gt;Lastly, the allocator can be used as a mock library, improving unit testing. Unlike &lt;em&gt;std::new&lt;/em&gt;, the allocator under the developers control. Because of this, it is easier to simulate out of memory errors and other difficult to reproduce situations.&lt;/p&gt;

&lt;p&gt;Conclusion&lt;/p&gt;

&lt;p&gt;The binary buddy system is a conceptually simple scheme which completely eliminates external fragmentation. When combined with C++ templates, all fragmentation may be eliminated. Offering the application developer space-efficient access to dynamic memory.&lt;/p&gt;

&lt;p&gt;Custom allocators are difficult. Difficult to implement, even more difficult to out perform your platforms default allocator. However, the reasons for custom allocators are more than just performance. Interesting debugging tools, fast initialization, and more robust software though better testing are but a few enhancements afforded by custom memory allocators.&lt;/p&gt;

&lt;p&gt;Bibliography&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Lawerence Rauchwerger Alin Jula. Two memory allocators that use hints to improve locality. &lt;em&gt;Texas A&amp;amp;M University&lt;/em&gt;, 2009.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Mel Gorman. _Understanding the Linux Virtual Memory Manager. _Prentice Hall, 2004.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;T. Johsson and T. Davis. Space efficient parallel buddy memory management. &lt;em&gt;Proceedings of the Fourth IEEE Internations Conference on
Computing and Information (ICCI&amp;rsquo;92)&lt;/em&gt;, 1992.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Nicolai M. Josuttis.&lt;em&gt;The C++ Standard Library&lt;/em&gt;. Addison-Wesley, 2005.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;J.M.P. van Waveren. From texture virtualizaton to massive parallelization.In &lt;em&gt;id Tech 5 Challenges&lt;/em&gt;, 2009. [](&lt;a href=&#34;http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf)[http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf](http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf&#34;&gt;http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf)[http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf](http://mrl.cs.vsb.cz/people/gaura/agu/05-JP_id_Tech_5_Challenges.pdf&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Making C&#43;&#43; like Python: The Anderson Smart Pointer Pattern</title>
      <link>http://codestrokes.com/2011/10/making-c-like-python-the-anderson-smart-pointer-pattern/</link>
      <pubDate>Sun, 23 Oct 2011 19:00:21 +0000</pubDate>
      
      <guid>http://codestrokes.com/2011/10/making-c-like-python-the-anderson-smart-pointer-pattern/</guid>
      <description>&lt;p&gt;Choosing to use C++ brings the additional complexity of memory management.  Dennis Ritchie once stated: The C Programming Language — A language which combines the flexibility of assembly language with the power of assembly language. C++ inherits much of that _flexibility, _however, this &lt;a href=&#34;http://www.infoq.com/presentations/Are-We-There-Yet-Rich-Hickey&#34;&gt;incidental complexity&lt;/a&gt;, can be relegated to a single class, leaving you with the high-level elegance of Python. RAII help with this additional complexity, however without a pattern for guidance implementing RAII consistently can be difficult, defeating the safety it provides.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Resource Acquisition Is Initialization (&lt;a href=&#34;http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization&#34;&gt;RAII&lt;/a&gt;) is a powerful tool for managing resources.  RAII &lt;a href=&#34;http://www.research.att.com/~bs/bs_faq2.html#finally&#34;&gt;justifies&lt;/a&gt; the apparent missing finally clause. Stroustrup claims that with proper RAII,  &lt;a href=&#34;http://www.research.att.com/~bs/bs_faq2.html#finally&#34;&gt;finally&lt;/a&gt; is not required. D also &lt;a href=&#34;http://www.d-programming-language.org/exception-safe.html&#34;&gt;implements&lt;/a&gt; RAII with scope operators. Ok, so RAII is powerful, but what is it?&lt;/p&gt;

&lt;p&gt;In C++, destructors are the only entity guaranteed to execute after an exception.  So resources which need to be automatically reclaimed need  to acquire at initialization, and release at destruction.  Such resources must be declared on the stack, to permit this idiom.&lt;/p&gt;

&lt;p&gt;Writing exception-safe code, e.g. managing resources throughout exceptions is difficult, and while RAII makes it easier, managing RAII correctly is difficult without a pattern. A colleague of mine, &lt;a href=&#34;http://www.chrisanderman.com/&#34;&gt;Anderson&lt;/a&gt;, developed a fantastic pattern/&lt;a href=&#34;http://erdani.com/publications/cuj-2005-12.pdf&#34;&gt;policy&lt;/a&gt; using smart pointers which makes RAII automatic.&lt;/p&gt;

&lt;p&gt;Two patterns compose the Anderson Smart Pointer Pattern: Factory Constructor, and PIMPL.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#ifdef _WIN
#include &amp;lt;memory&amp;gt;
#else
#include &amp;lt;tr1/memory&amp;gt;
#endif

class Name
{
public:
#ifdef _WIN
    typedef std::shared_ptr Ptr; //This uses the class as a namespace.
    typedef std::weak_ptr WeakPtr;
#else
    typedef std::tr1::shared_ptr Ptr;
    typedef std::tr1::weak_ptr WeakPtr;
#endif
    static name::Ptr construct(); //Factory Constructor
    virtual ~name();
private:
    Name(); //Notice the constructor is private
    name::WeakPtr self; //self (from python), replaces this
};

Name::Ptr Name::construct()
{
    Name::Ptr c(new Name());
    //Self completes the PIMPL idiom,
    //thereby hiding all behavior behind a safe, reference counted wall
    c-&amp;gt;self = c;
    return c;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This pattern is used as an RAII &lt;a href=&#34;http://erdani.com/publications/cuj-2005-12.pdf&#34;&gt;policy&lt;/a&gt;. Using the pattern liberally can eliminate new and delete from your program, and you will not leak memory. Even with multiple exceptions, you&amp;rsquo;re &lt;a href=&#34;https://bitbucket.org/jwright/cse310-red-black-tree/overview&#34;&gt;program will not leak&lt;/a&gt;.  Creating an instance of an RAII class is easy now:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Name::Ptr myInstance = Name::construct();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This Pattern will make one extra virtual call as it performs the reference counting, but the performance hit is typically nominal compared to the safety it provides to the system. The Anderson Smart-Pointer Pattern increases robustness of your programs, but interestingly it also provides a new elegance. Since one is not managing memory, and resources constantly, it makes C++ perform more like a high level language. For example, I implemented a &lt;a href=&#34;https://bitbucket.org/jwright/cse310-red-black-tree/src/d787e75b724a/BaseCode/RedBlackTree.cpp#cl-137&#34;&gt;red black tree&lt;/a&gt; using this pattern.  I didn&amp;rsquo;t need to worry about deleting nodes, just the requirements of my program. With the incidental complexity relegated to a single class, I am left with the elegant, expressiveness of Python, yet retain the raw performance of C++.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parallel Game-of-Life</title>
      <link>http://codestrokes.com/2011/10/parallel-game-of-life/</link>
      <pubDate>Sun, 23 Oct 2011 17:55:47 +0000</pubDate>
      
      <guid>http://codestrokes.com/2011/10/parallel-game-of-life/</guid>
      <description>

&lt;p&gt;Conway&amp;rsquo;s &lt;a href=&#34;http://www.bitstorm.org/gameoflife/&#34;&gt;Game of Life&lt;/a&gt; is a dramatic illustration of emmergent behavior; that a seemingly complex system, such as cell mitosis can be governed by a set of simple rules. OpenMP is a fantastic set of language extensions which allows one to add dramatic parallelism without complex thread management.  As a demonstration of &lt;a href=&#34;http://openmp.org/wp/&#34;&gt;OpenMP&lt;/a&gt;&amp;rsquo;s simplicity I implemented the Game of Life. The code and all analysis is available on &lt;a href=&#34;https://bitbucket.org/jwright/parallel-game-of-life&#34;&gt;bitbucket.org&lt;/a&gt;.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;In a real program, it common to have swathes of code which cannot be made parallel. OpenMP&amp;rsquo;s limited perspective on data limits one further.  As such, OpenMP is most effective when the data is decomposed into independently manageable chunks. To evaluate the performance affect of OpenMP on my implementation I used a single Base Class to implement the serial portion of the code. Each child class makes small modifications to the generation calculation, decomposing the data in different ways.  I made three decompositions:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Decomposition by Rows&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Decomposition by Columns&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Random Decomposition by Cell&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Interestingly, the relative performance of each mechanism was quite volatile. The serial version of the code is quite simple. Basically, calculate each live/die action for every cell then, after all calculations are made, commit the updates in one atomic action.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void GameGrid::CalculateGeneration()
{
    list delayedUpdates;

    for(size_t col = 0; col &amp;lt; GetGridSize(); ++col)
    {
        for(size_t row = 0; row &amp;lt; GetGridSize(); ++row)
        {
            uint32_t livingNeighbors = CountLivingNeighbors(col, row);
#ifdef DEBUG
            cout &amp;lt;&amp;lt; &amp;quot;Row: &amp;quot; &amp;lt;&amp;lt; row
                &amp;lt;&amp;lt; &amp;quot;Col: &amp;quot; &amp;lt;&amp;lt; col
                &amp;lt;&amp;lt; &amp;quot;: &amp;quot; &amp;lt;&amp;lt; livingNeighbors &amp;lt;&amp;lt; endl;
#endif
            Update u;
            u.threadId = omp_get_thread_num();
            u.position = &amp;amp;(Grid[col][row]);
            u.threadPosition = &amp;amp;(GridThreads[col][row]);
            if(Grid[col][row]) //If Cell is alive
            {
                if(livingNeighbors = 4)
                {
                    //Kill Cell
                    u.updateValue = false;
                    delayedUpdates.push_back(u);
                }
                /* else remain alive */
            }
            else
            {
                if(livingNeighbors == 3)
                {
                    //ConceiveCell
                    u.updateValue = true;
                    delayedUpdates.push_back(u);
                }
            }

        }
    }
    commitUpdates(delayedUpdates);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Even this simple routine can generate incredible emergent behavior.&lt;/p&gt;

&lt;p&gt;Your browser does not support the video tag.&lt;/p&gt;

&lt;p&gt;Now, we have a serial platform to extend into a parallel one. First we extend the base class with simple inheritance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class GameGridParallelCol : public GameGrid
{
    public:
        typedef std::tr1::shared_ptr Ptr; ///@note The Anderson Smart Pointer Idiom
        typedef std::tr1::weak_ptr WeakPtr;
        static GameGridParallelCol::Ptr construct(string filename, size_t size);
        virtual ~GameGridParallelCol();
        virtual void CalculateGeneration();
    protected:
    private:

        GameGridParallelCol(string filename, size_t size);
        GameGridParallelCol::WeakPtr self;

};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The using OpenMP Directives add col decomposition:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void GameGridParallelCol::CalculateGeneration()
{
    vector delayedUpdates[omp_get_max_threads()]; //Create duplicate update lists, to avoid critical sections.
   for(size_t row = 0; row &amp;lt; GetGridSize(); ++row)
    {
#pragma omp parallel for
        for(size_t col = 0; col &amp;lt; GetGridSize(); ++col)
        {
            uint32_t livingNeighbors = CountLivingNeighbors(col, row);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is the power of OpenMP, its simplicity.  OpenMP exposes a set of #pragma functions which apply parallelism to the beginning of a scope block, and a barrier at the end of the scope block. Automatic parallelism, it doesn&amp;rsquo;t get easier than this. However OpenMP&amp;rsquo;s simplicity does hamper it in a few ways. OpenMP directives for instance, cannot batch C++ iterators. Now we have a thread pool which will run segments of the game of life in parallel.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_420&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;792&amp;rdquo; caption=&amp;ldquo;Column Order Decomposition&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/Screenshot-at-2011-10-22-215034.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/Screenshot-at-2011-10-22-215034.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;The right half of the image illustrates each thread, one for each color, as it updates a section of the game grid.  (Decomposition into rows is left as an exercise). Extending this we can make a fully parallel version.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#pragma omp parallel for collapse(2) schedule(dynamic)
   for(size_t row = 0; row &amp;lt; GetGridSize(); ++row)
    {
        for(size_t col = 0; col &amp;lt; GetGridSize(); ++col)
        {
            uint32_t livingNeighbors = CountLivingNeighbors(col, row);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Rendering the following:&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_422&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;792&amp;rdquo; caption=&amp;ldquo;Full data decomposition with dynamic thread balancing&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/CorrectedFullThreadRender.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/CorrectedFullThreadRender.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;Now we have a fully parallel version where threads calculate cells at random, as the thread is available. Strangely, this isn&amp;rsquo;t always the fastest algorithm.&lt;/p&gt;

&lt;h2 id=&#34;analysis:d59e23fa831b00ad3ec19e2fe0a18821&#34;&gt;Analysis&lt;/h2&gt;

&lt;p&gt;No single decomposition wins out. As such there is no generalization such that one threading mechanism is faster than another in all cases. The Full threading model was mst consistant, but the Row and Column decompositions actually got slower as more cores were added.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_423&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;695&amp;rdquo; caption=&amp;ldquo;6-core Speedup&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/fitted-speedup.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/fitted-speedup-1024x768.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_424&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;695&amp;rdquo; caption=&amp;ldquo;12-core Speedup&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/fitted-speedup1.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/10/fitted-speedup1-1024x768.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;[/caption]&lt;/p&gt;

&lt;p&gt;Most interestingly, the row and column performance goes down with more cores, while the full decomposition stays pretty constant. I do not have a reason why this is happening.&lt;/p&gt;

&lt;h2 id=&#34;conclusion:d59e23fa831b00ad3ec19e2fe0a18821&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;OpenMP makes adding parallelism to a serial program easy. The constructs allow one to sprinkle parallel code throughout the program, and the measure the performance boost. Sometimes it may be prudent to dive in deeper and manually thread some section of code, especially when using complex C++ constructs such as iterators, but if OpenMP meets the need, then its a low-cost, cross-platform mechanism.  Furthermore, OpenMP is exposed as a set of #pragma functions. Since #pragmas are by definition an extension to the language, if the compiler doesn&amp;rsquo;t understand the directives, they are simply ignored. This allows one to liberally use OpenMP, and if the compiler of choice doesn&amp;rsquo;t support the OpenMP directives, OpenMP will not break the build. OpenMP is a fantastic tool.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Good Tools, Excellent Results</title>
      <link>http://codestrokes.com/2011/08/good-tools-excellent-results/</link>
      <pubDate>Sun, 21 Aug 2011 07:23:25 +0000</pubDate>
      
      <guid>http://codestrokes.com/2011/08/good-tools-excellent-results/</guid>
      <description>&lt;p&gt;This semester for the C++ practicum we are building a clone of Zork.  Like many games of the genre, Zork is driven by a database.  Our implementation is a JSON database.  I chose JSON for a few reasons, but most importantly because its a human readable format that&amp;rsquo;s simple to understand.  I started by editing JSON files by hand in a text editor, however I found very quickly that investigating in a quick tool greatly improved my quality.&lt;/p&gt;

&lt;p&gt;&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;I chose JSON as a format. Next, I needed a schema.  Currently the schema design is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Clearing&amp;quot;: {
 &amp;quot;Description&amp;quot;: &amp;quot;You are in a clearing. There is a berry bramble to your right.&amp;quot;,
 &amp;quot;Exits&amp;quot;: {
     &amp;quot;East&amp;quot;: &amp;quot;Up a Tree&amp;quot;,
     &amp;quot;North&amp;quot;: &amp;quot;Grating Room&amp;quot;,
     &amp;quot;South&amp;quot;: &amp;quot;Clearing&amp;quot;,
     &amp;quot;West&amp;quot;: &amp;quot;&amp;quot;
 },
 &amp;quot;Items&amp;quot;: [&amp;quot;Berries&amp;quot;, &amp;quot;Sword&amp;quot;]
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If nothing else its simple. So I started to layout the map, editing the JSON database directly in my text editor.  I found that even with such a simple schema, in a simple format such as JSON, it is incredible difficult to manage more than a few rooms.  I needed a better tool, a Map Editor.&lt;/p&gt;

&lt;p&gt;Python to the rescue.  Using PyQt and Qt Designer I was able to whip up a dirty little map editor in an evening (totally about 3 hours).&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2011/08/Screenshot-Practicum-Game-Editor.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2011/08/Screenshot-Practicum-Game-Editor-1024x786.png&#34; alt=&#34;&#34; /&gt;
&lt;/a&gt;With this I can not manage a much larger database, giving my players a much more immersive environment.  Secondly, my students can use and even extend the tool to make even better game play.&lt;/p&gt;

&lt;p&gt;I wasted quite a bit of time hand editing JSON files, when such a simple tool could be built in less than half the time.  I took it as just another example of, &amp;ldquo;Sometimes you have to slow down to speed up.&amp;rdquo;  Take time to make your tools work.  Take time to make the right tools, and it will always pay dividends.&lt;/p&gt;

&lt;p&gt;Source Code is available here: &lt;a href=&#34;https://bitbucket.org/jwright/gamecomponents&#34;&gt;https://bitbucket.org/jwright/gamecomponents&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>