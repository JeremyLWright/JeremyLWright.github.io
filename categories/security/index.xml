<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Security on Code Strokes</title>
    <link>http://www.codestrokes.com/categories/security/</link>
    <description>Recent content in Security on Code Strokes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 03 May 2014 20:56:49 +0000</lastBuildDate>
    <atom:link href="http://www.codestrokes.com/categories/security/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Design for Testability via Security </title>
      <link>http://www.codestrokes.com/2014/05/design-for-testability-via-security/</link>
      <pubDate>Sat, 03 May 2014 20:56:49 +0000</pubDate>
      
      <guid>http://www.codestrokes.com/2014/05/design-for-testability-via-security/</guid>
      <description>

&lt;p&gt;I was discussing bootloader design with a colleague of mine the other day. We were attempting to load new a third-party hardware component. The device has a poor protocol, and a useless verification step. This discussion got me thinking however how the concepts used to build a strong self-enforcing security protocol, also apply to building a testable, and reliable communication protocol. Thus, security helps us build better products not because they are secure, but because they are verifiable.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
This idea initially struck me as strange, since many of the secure software interfaces I&amp;rsquo;ve used in the past, are quite obtuse. This is not a fundamental aspect of security, by rather an artifact of poor design (think OpenSSL). This is sad, since security is already a difficult concept, and requires a great deal of study to maintain throughout the life cycle of a product. Secure interfaces should make security easier, not more difficult. This is however a separate rant. So back to the bootloader.&lt;/p&gt;

&lt;p&gt;This specific device is connected by a CAN bus. This is not critical to my argument except the fact that CAN is a reliable, but slow and message order is not guaranteed. In fact, within a window of 4 packets, order is essentially random. Think about this for a moment: load firmware with random message order. The goal is to design a protocol to work with this. Firmware loading fits into a three step process: Prepare, Load, Verify. This process works independent of underlying storage techniques. For example, NAND must be erased on a full page boundary, that can be done in the prepare step. Loading to a file system, Prepare might be a simple NOP.&lt;/p&gt;

&lt;p&gt;Firstly, know that the final, verification step is essential. Some environments, the bootloader runs out of RAM, if the load process fails, and the hardware reboots without verification, the bootloader may no longer function, and you just build a sweet digital brick. So verification must check that the firmware the user attempted to load, matches the firmware written to the flash. There are several mechanisms to verify this. The hardware my colleague and I are working with, simply reads the flash back to you. At a high level this sounds fine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Loader ---&amp;gt; Send Data     ---&amp;gt; Bootloader
Loader ---&amp;gt; Data Complete ---&amp;gt; Bootloader
Loader ---&amp;gt; Verify        ---&amp;gt; Bootloader
Loader &amp;lt;--- Send Data     &amp;lt;--- Bootloader
Loader Loader Verifies data matches.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remember, message order is random. If the bootloader dumps its flash back on the CAN bus, without a sequence number or flash addresses, the data that comes back is completely useless. Each data packet is intact, but is position within the overall data block is unknown. The best one can do is probabilisticly reorder the packets to attempt to get a confidence the bootloader has the same data we attempted to send. Okay, so what would be better? Lets model this as a security problem and design a secure document sending protocol.&lt;/p&gt;

&lt;h3 id=&#34;prepare:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Prepare&lt;/h3&gt;

&lt;p&gt;Alice and Bob want to exchange a document. (Any protocol can be made more &amp;ldquo;secure&amp;rdquo; by describing it with &lt;a href=&#34;https://xkcd.com/1323/&#34;&gt;Alice and Bob.&lt;/a&gt;) The communication channel is UDP, untrusted, and public. How should Alice and Bob communicate? Every security protocol starts with authentication. Bob wants to verify the sender is Alice. Alice wants to verify it&amp;rsquo;s sending the document to Bob, and not someone else. So lets negotiate a key based on a preshared secret. This will form the prepare step of our high-level bootloader model.
&lt;table &gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice generates a nonce.
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob waiting for message.
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice encrypts bob_public_key(nonce_alice:sha256(nonce_alice))
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;-&amp;gt;
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr &gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Alice
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;&amp;lt;-
&lt;/td&gt;&lt;/p&gt;

&lt;p&gt;&lt;td &gt;Bob decrypts the message.
Bob generates a new nonce. Bob encrypts
alice_public_key(nonce_bob:sha256(nonce_bob):nonce_alice:sha256(nonce_alice))&lt;/p&gt;

&lt;p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;Alice now has Bob&amp;rsquo;s nonce. Bob has Alice&amp;rsquo;s nonce. Any listening attacker only has 2 messages of cipher text. Bob know&amp;rsquo;s the message was sent from Alice because only Alice has Alice&amp;rsquo;s private key,thus only Alice could have made the nonce message. Bob knows the nonce was intentional because Alice included the secure hash of the nonce.&lt;/p&gt;

&lt;p&gt;This protocol is protected against replay attack since Bob decrypts the nonce and hash, and reencrypts with Alice&amp;rsquo;s public key. This allows Alice to verify Bob received her original message. Furthermore the messages are protected against manipulation because all messages include hashes. Bob, and Alice are authenticated. Additionally, they share a new, secret session key.&lt;/p&gt;

&lt;p&gt;Alice builds the session key, &amp;ldquo;sha256(nonce_bob:nonce_alice)&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;Bob builds the session key, &amp;ldquo;sha256(nonce_bob:nonce_alice)&amp;ldquo;.&lt;/p&gt;

&lt;p&gt;Now only Bob and Alice at this time instance can have this new shared secret. Alice and Bob can now communicate securely. &lt;del&gt;Let&amp;rsquo;s load some firmware to Bob now.&lt;/del&gt; Let&amp;rsquo;s transfer a document to Bob now.&lt;/p&gt;

&lt;h3 id=&#34;transfer:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Transfer&lt;/h3&gt;

&lt;p&gt;Alice creates a document and signs it e.g. document:alice_private_key(sha256(document)).  Notice that Alice&amp;rsquo;s private key is used to encrypt here. This is correct. We want Bob to receive the document, create a hash of the document. Bob then uses Alice&amp;rsquo;s public key to &amp;ldquo;encrypt&amp;rdquo; the signature sent by Alice. He will get the plain text hash, and compare. The signature does not protect the hash i.e. it does not provide confidentiality since anyone can decrypt with the public key. Instead the signature provides integrity. The hash protects that the document was unchanged. The signature of the hash protects that the hash was computed only by Alice.&lt;/p&gt;

&lt;p&gt;Alice breaks up the document into packets to send over UDP. Each packet includes a sequence number and a hash of that message.&lt;/p&gt;

&lt;p&gt;packet = aes(session_key, i:document[i]:sha256(i:document[i]))&lt;/p&gt;

&lt;p&gt;The session key encrypts the entire message to provide confidentiality. This also strengthens the Man in the middle attack, since this session_key is ephemeral. Since it exists for only this authenticated session, an attacker cannot resend this data later to Bob. The sha256 hash provides integrity i.e. &lt;del&gt;transmission errors&lt;/del&gt; malicious corruption. Bob verifies each individual packet by calculating the has of the received document[i], and comparing it. If the packets arrive out of order, which in &lt;del&gt;CAN&lt;/del&gt; UDP they will, Bob can sort them.&lt;/p&gt;

&lt;p&gt;Once Bob has the entire message he can verify the signature.  Bob now has the document, all listeners only have cipher version of the document. Furthermore, Bob can verify the entire document is valid. Bob will &lt;del&gt;erase his flash, and load the new firmware into memory&lt;/del&gt; PROFIT!&lt;/p&gt;

&lt;h3 id=&#34;verify:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Verify&lt;/h3&gt;

&lt;p&gt;The device my colleague and I are trying to fix simply dumped the document back to Alice.  Essentially:&lt;/p&gt;

&lt;p&gt;packet = document[i]&lt;/p&gt;

&lt;p&gt;Each packet isn&amp;rsquo;t protected from corruption. The order of the document is unverifiable. The best Alice can do is attempt to verify multiple times hoping the document messages randomly converge on the document Alice originally sent. This is the same as using &lt;a href=&#34;http://en.wikipedia.org/wiki/Bogosort&#34;&gt;Bogosort&lt;/a&gt; as a verification step. Not awesome. Instead we&amp;rsquo;ve built up some very secure machinery to &lt;del&gt;load software reliably&lt;/del&gt; transfer a document securely.&lt;/p&gt;

&lt;p&gt;One method, although rather naive would be for Bob to send back the document to Alice in the same manner, encrypting each packet and the final signature. This however is very wasteful. Instead Alice only needs to confirm that Bob has the document in its entirely, that it is in the flash, and that all packets were loaded in the correct order. Bob simply needs to send a signature. Bob then reads his flash, and calculates a sha256. Bob then sends 1 message:&lt;/p&gt;

&lt;p&gt;packet = aes(session_key, bob_private_key(sha256(flash_read)))&lt;/p&gt;

&lt;p&gt;The packet is confidential because it is encrypted by aes. The message is protected from integrity because Alice already has the hash, she simple needs to verify that it matches the know value. Note that if Alice didn&amp;rsquo;t have the hash already we would include a hash of the hash to provide further integrity. Alice knows that it was Bob who verified the flash because the hash is signed with Bob&amp;rsquo;s key. Lastly, Alice knows the message is part of this load session and not a previous one replayed by an attacker because the whole message is encrypted by a session key.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:9d165bcce3b5cd91e19ccd1b43634f44&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Alice and Bob now have a protocol secure against a number of attacks, but how is this useful for a bootloader? Each attack can be modeled as random noise, transmission errors, or other external effects would impede the flow of traffic. Security simply provides a more common vernacular for discussing transmission issues. It&amp;rsquo;s also easier to reason about adversarial attackers rather than electrical interference. By translating the problem into a security one, we can model all these affects as &amp;ldquo;bad people&amp;rdquo; and it is a lot more fun to slay dragons, than it is to protect against some amorphous something.&lt;/p&gt;

&lt;p&gt;Okay, but what does this have to do with testability? Ah. It&amp;rsquo;s subtle, but the same process we took to make our protocol secure also made each step verifiable. For instance, the final verification step could have been as simple as Bob sending an ACK that he verified the document&amp;rsquo;s signature. This however isn&amp;rsquo;t secure. An ACK can be faked, or replayed. Instead Bob build a cryptographically secure signature for Alice to verify. From a tester&amp;rsquo;s perspective Alice is the &amp;ldquo;verifier&amp;rdquo;, and Bob generates test data. Bob cannot be trusted to verify something himself, the test must generate auditable output. Thus the same process which drove us to make a secure response, also generated a auditable one for the tester to report. Thus security is more useful than simply protecting our data, it helps us design better products.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Thunk on Laziness</title>
      <link>http://www.codestrokes.com/2013/10/a-thunk-on-laziness/</link>
      <pubDate>Sun, 27 Oct 2013 23:00:17 +0000</pubDate>
      
      <guid>http://www.codestrokes.com/2013/10/a-thunk-on-laziness/</guid>
      <description>&lt;p&gt;I originally approached Haskell excited, and wide-eyed mystified by the type theory. Type became my golden hammer. In my C programs I typedef&amp;rsquo;d everything so it&amp;rsquo;d have a &amp;ldquo;unique&amp;rdquo; type. I was cautious with my casting. I was hooked. I had an intuitive understanding of laziness, as implemented by Haskell, that would allow one to write&amp;rdquo;streaming&amp;rdquo; algorithms. That is programs that deal with data in an online way to process data as it streams through. While that maybe true, you know what else can do that? C.
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
I recently has a problem to extract logs from a product at work. The existing solution e.g. the solution I wrote the week before, was exponential in time. We had a problem. We had to extract the logs, and separate them by an sentinel in the file, encrypt the files, compress them, then copy the output to a thumbdrive. The only problem we didn&amp;rsquo;t have enough RAM to store the entire file in memory, and we didn&amp;rsquo;t have enough flash to create temporary files.  I needed a streaming algorithm.&lt;/p&gt;

&lt;p&gt;My first approach was to use UNIX pipes and filter data through sed | gzip | openssl. This worked, but required multiple workarounds to generate the sed expressions, eventually resulting in exponential time.  The second time, I was discussing with my co-worker, the virtues of compiled code versus shell scripts. In that vain I started looking into openssl as a library rather than an executable. You know who has streaming algorithms? OpenSSL. OpenSSL, has a fantastic abstraction called BIO_, Basic Input/Output. Which are simply functions you connect together in a chain to process data. The BIO interface is designed to allow one to work with SSL encrypted sockets in an intuitive way. For our use case we simply connected an zlib BIO -&amp;gt; AES BIO -&amp;gt; file sink. Write to the zlib, and watch the data compress, and write to the thumbdrive in one swoop, no laziness, thunking, or fancy data structure fusion required. The result: linear time.&lt;/p&gt;

&lt;p&gt;So the lesson here isn&amp;rsquo;t a technological one, but a personal one about myself. Don&amp;rsquo;t reach for a new technology to solve something. Look deeper into the root of the problem, and even a language as &amp;ldquo;dumb&amp;rdquo; and &amp;ldquo;simple&amp;rdquo;, and &amp;ldquo;old&amp;rdquo; as C, can provide the fastest, optimal solution.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux User&#39;s Group CTF 2013</title>
      <link>http://www.codestrokes.com/2013/09/linux-users-group-ctf-2013/</link>
      <pubDate>Sun, 08 Sep 2013 21:58:06 +0000</pubDate>
      
      <guid>http://www.codestrokes.com/2013/09/linux-users-group-ctf-2013/</guid>
      <description>&lt;p&gt;This past weekend we held another capture the flag event at the Arizona State University&amp;rsquo;s Linux User&amp;rsquo;s Group. It had more of a system admin focus than security cracking exploits, but it was fun an nontheless a diverse learning experience for all those involved. However, almost immediately, I realized the number one rule in CTF, nothing is off limits!
&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;
The game was organized into two parts, a game server which collected the the scores and displayed the point totals of all teams in real-time, and the virtual servers (hosted on Amazon EC2) which contained the actual games. Players were encouraged to break into teams, and register themselves on the game server. The game server would assign the team a virtual machine, and the team could log in via SSH to behind hacking. Five minutes into the registration process, one team attempted a SQL injection attack against the game server.&lt;/p&gt;

&lt;p&gt;[caption id=&amp;ldquo;attachment_1189&amp;rdquo; align=&amp;ldquo;aligncenter&amp;rdquo; width=&amp;ldquo;700&amp;rdquo;]&lt;a href=&#34;http://www.codestrokes.com/wp-content/uploads/2013/09/Final-Score.png&#34;&gt;&lt;img src=&#34;http://www.codestrokes.com/wp-content/uploads/2013/09/Final-Score-1024x429.png&#34; alt=&#34;Notice the SQL Injection attempt&#34; /&gt;
&lt;/a&gt; Notice the SQL Injection attempt[/caption]&lt;/p&gt;

&lt;p&gt;I wrote the game server as a django webapp, to collect points, and serve as a dashboard for the players. We logged in at the front of the room and displayed the graph on the front projector. It was a very motivating aspect of the game, however I never planned on it being part of the game itself.  First lesson learned in capture the flag, nothing is off limits. Luckily, django does the right thing, and sanitizes form data automatically. The server was unscathed, the failed injection attempt was displayed for all the teams to see. I&amp;rsquo;m currently compiling additional aspects of what worked and what didn&amp;rsquo;t so check back soon. The CTF was a fantastic event this year, and really motivated newbies, and elites a like.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Capture the Flag - Running a Hacking Competition</title>
      <link>http://www.codestrokes.com/2012/04/capture-the-flag-running-a-hacking-competition/</link>
      <pubDate>Mon, 30 Apr 2012 02:38:44 +0000</pubDate>
      
      <guid>http://www.codestrokes.com/2012/04/capture-the-flag-running-a-hacking-competition/</guid>
      <description>&lt;p&gt;Black-Hat hacking in an controlled environment, like this, is an important skill for software developers. The &lt;a href=&#34;http://en.wikipedia.org/wiki/The_Art_of_War&#34;&gt;Art of War&lt;/a&gt; describes knowing one&amp;rsquo;s enemy, and with the prevalence of internet-enabled applications today, it has never been more critical to know how the &amp;ldquo;enemy&amp;rdquo; can take down a system. While capture-the-flag is a fun, and exciting intellectual game, it is serious training for software engineers of all types, and skill levels. I recently setup a small capture the flag event for the &lt;a href=&#34;http://asulug.org/&#34;&gt;Arizona Linux User&amp;rsquo;s Group&lt;/a&gt;, and it was very fun.&lt;/p&gt;

&lt;p&gt;To setup a catpure the flag event, here are a few guidelines I found useful:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Brute-force attacks are no fun. There is no intellect involved, and while one brute forces the box, no one else can have a try.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Setup a box to provide services to the rest of the network. Clearly define this box as off limits.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Use virtual machines for target systems. This allows one to restore the system from an image if someone goes too far.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Physically separate the game from any other networks.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Provide ISOs of &lt;a href=&#34;http://www.backtrack-linux.org/&#34;&gt;Backtrack&lt;/a&gt; Linux&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;!&amp;ndash; more &amp;ndash;&amp;gt;Organizing a hacking event takes time, and planning.&lt;/p&gt;

&lt;p&gt;For this event I setup 3 systems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A host system which provided DNS, and hosted the virtual machines.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A Windows 2000 virtual machine.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A Ubuntu 12.04 virtual machine.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The windows 2000 box has a pile of vulnerabilities. These vulnerabilities have been scripted into hacking applications, which allow automatic take down of the system. This is not necessarily a bad thing however, since it does provide a level of accomplishment, and is conducive to hiding clues. One clue I thought of after this event, was to set the &lt;a href=&#34;http://en.wikipedia.org/wiki/Steganography&#34;&gt;background&lt;/a&gt; to something with &lt;a href=&#34;http://en.wikipedia.org/wiki/Steganography&#34;&gt;hidden&lt;/a&gt; data in it. Tools exist to analyse the entropy of an image to determine if it contains data. One could encode the hash of some password into the image, then use a rainbow table to decrypt the hash.&lt;/p&gt;

&lt;p&gt;Essentially, break down the event into a series of quests. All quests lead to the same end i.e. network domination and a free round at the happy hour, but some paths are different than others. One quest may have more intellectual clues stenography, SQL injection, riddles which yield a password a la King&amp;rsquo;s Quest. Another path may be fraught with vulnerabilities. The latter requires a encyclopedic knowledge of known vulnerabilities to crack this quest. I recommend making this path longer, since Google skills can shorten it immensely.&lt;/p&gt;

&lt;p&gt;Next, determine how the game will be scored and clearly post this information. For the latest event I hosted, I posted all the objectives at the front of the room, and wrote someones name as each objective was acquired. This worked well, but a more interactive system would be far more exciting. Something that showed the dominance and protection of different network factions. Honestly, this is more work, but certainly provides more excitement to the game.&lt;/p&gt;

&lt;p&gt;Lastly, make the event fun, and provide other activities for those who don&amp;rsquo;t want to hack. This can be a very fun event, yet still important to learning how to build secure software. Ping me if you have other ideas for a hacking event, or post in the comments :-).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>